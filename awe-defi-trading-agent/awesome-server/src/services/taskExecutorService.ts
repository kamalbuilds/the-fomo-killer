import { ChatOpenAI } from '@langchain/openai';
import { HumanMessage, SystemMessage, AIMessage } from '@langchain/core/messages';
import { logger } from '../utils/logger.js';
import { Task } from '../models/task.js';
import { MCPAuthService } from './mcpAuthService.js';
import { getTaskService } from './taskService.js';
import { HTTPMCPAdapter } from './httpMcpAdapter.js';
import { taskExecutorDao } from '../dao/taskExecutorDao.js';
import { TaskStepResult, TaskExecutionResult, WorkflowExecutionStatus } from '../models/taskExecution.js';
import { HttpsProxyAgent } from 'https-proxy-agent';
import { MCPManager } from './mcpManager.js';
import { messageDao } from '../dao/messageDao.js';
import { MessageType, MessageIntent, MessageStepType } from '../models/conversation.js';
import { conversationDao } from '../dao/conversationDao.js';
import { resolveUserLanguage, getLanguageInstruction, SupportedLanguage } from '../utils/languageDetector.js';

import { MCPInfo } from '../models/mcp.js';
import { MCPToolAdapter } from './mcpToolAdapter.js';
import { mcpNameMapping } from './predefinedMCPs.js';
import { IntelligentWorkflowEngine } from './intelligentWorkflowEngine.js';

// ğŸ›ï¸ æ™ºèƒ½å·¥ä½œæµå…¨å±€å¼€å…³ - è®¾ç½®ä¸ºfalseå¯å¿«é€Ÿå›é€€åˆ°åŸæœ‰æµç¨‹
const ENABLE_INTELLIGENT_WORKFLOW = true;

// æ·»åŠ LangChainé“¾å¼è°ƒç”¨æ”¯æŒ
import { RunnableSequence, RunnablePassthrough } from '@langchain/core/runnables';
import { StructuredTool } from '@langchain/core/tools';
import { z } from 'zod';
import fa from 'zod/dist/types/v4/locales/fa.js';

const proxy = process.env.HTTPS_PROXY || 'http://127.0.0.1:7890';
const agent = new HttpsProxyAgent(proxy);
// è·å–taskServiceå®ä¾‹
const taskService = getTaskService();

/**
 * Task Executor Service
 * é€šç”¨ä»»åŠ¡æ‰§è¡Œå™¨ï¼Œè´Ÿè´£æ‰§è¡ŒMCPå·¥ä½œæµå¹¶ç”Ÿæˆç»“æœ
 * ä¸åŒ…å«ä»»ä½•ç‰¹å®šMCPçš„ä¸šåŠ¡é€»è¾‘
 */
export class TaskExecutorService {
  private llm: ChatOpenAI;
  private mcpAuthService: MCPAuthService;
  private httpAdapter: HTTPMCPAdapter;
  private mcpManager: MCPManager;
  private mcpToolAdapter: MCPToolAdapter;
  private intelligentWorkflowEngine: IntelligentWorkflowEngine;
  
  constructor(httpAdapter: HTTPMCPAdapter, mcpAuthService: MCPAuthService, mcpManager: MCPManager) {
    this.httpAdapter = httpAdapter;
    this.mcpAuthService = mcpAuthService;
    this.mcpManager = mcpManager;
    
    // åˆå§‹åŒ–MCPToolAdapter
    this.mcpToolAdapter = new MCPToolAdapter(this.mcpManager);
    
    // åˆå§‹åŒ–æ™ºèƒ½å·¥ä½œæµå¼•æ“
    this.intelligentWorkflowEngine = new IntelligentWorkflowEngine();
    
    // åˆå§‹åŒ–ChatOpenAI
    this.llm = new ChatOpenAI({
      modelName: 'gpt-4o',
      temperature: 0.3,
      streaming: true,
      maxTokens: 16384, // å¤§å¹…å¢åŠ tokené™åˆ¶ï¼Œæ”¯æŒæ›´å¤§çš„æ•°æ®å¤„ç†
      apiKey: process.env.OPENAI_API_KEY
    });
  }
  
  /**
   * éªŒè¯å¹¶ç¡®ä¿MCPå®¢æˆ·ç«¯è¿æ¥æ­£å¸¸
   * @param mcpName MCPåç§°
   * @param userId ç”¨æˆ·ID
   * @returns éªŒè¯è¿‡çš„å®¢æˆ·ç«¯å®ä¾‹
   */
  private async ensureClientConnection(mcpName: string, userId?: string): Promise<any> {
    const connectedMCPs = this.mcpManager.getConnectedMCPs(userId);
    const isConnected = connectedMCPs.some(mcp => mcp.name === mcpName);
        
    if (!isConnected) {
      throw new Error(`MCP ${mcpName} not connected, please ensure MCP service is available`);
      }

    // éªŒè¯å®¢æˆ·ç«¯è¿æ¥çŠ¶æ€
    const client = this.mcpManager.getClient(mcpName, userId);
    if (!client) {
      throw new Error(`No client found for MCP: ${mcpName}`);
    }

    // æ£€æŸ¥å®¢æˆ·ç«¯å®é™…è¿æ¥çŠ¶æ€
    try {
      await client.listTools();
      logger.info(`âœ… Client connection verified for ${mcpName}`);
      return client;
    } catch (connectionError) {
      logger.error(`âŒ Client connection failed for ${mcpName}:`, connectionError);
      logger.info(`ğŸ”„ Attempting to reconnect ${mcpName}...`);
      
      // è·å–MCPé…ç½®ç”¨äºé‡è¿
      const mcpConfig = connectedMCPs.find(mcp => mcp.name === mcpName);
      if (!mcpConfig) {
        throw new Error(`MCP ${mcpName} configuration not found for reconnection`);
      }
      
      try {
        // å°è¯•é‡æ–°è¿æ¥
        await this.mcpManager.disconnect(mcpName, userId);
        await this.mcpManager.connect(mcpName, mcpConfig.command, mcpConfig.args, mcpConfig.env, userId);
          
        // éªŒè¯é‡è¿åçš„è¿æ¥
        const reconnectedClient = this.mcpManager.getClient(mcpName, userId);
        if (!reconnectedClient) {
          throw new Error(`Failed to get reconnected client for ${mcpName}`);
        }
        
        await reconnectedClient.listTools();
        logger.info(`âœ… Successfully reconnected ${mcpName}`);
        
        return reconnectedClient;
      } catch (reconnectError) {
        logger.error(`âŒ Failed to reconnect ${mcpName}:`, reconnectError);
        throw new Error(`MCP ${mcpName} connection failed and reconnection failed: ${reconnectError}`);
      }
    }
  }
  
  /**
   * é€šç”¨æ­¥éª¤è¾“å…¥å¤„ç†
   */
  private processStepInput(input: any): any {
    // å¦‚æœinputæ˜¯JSONå­—ç¬¦ä¸²ï¼Œå°è¯•è§£æå®ƒ
    if (typeof input === 'string' && input.startsWith('{') && input.endsWith('}')) {
      try {
        return JSON.parse(input);
      } catch (e) {
        logger.warn(`Input is not a valid JSON string, will be processed as regular string: ${input}`);
        return input;
      }
    }
    return input;
  }
  
  /**
   * ğŸ”§ æ–°å¢ï¼šæ ¹æ®schemaè‡ªåŠ¨åˆ›å»ºå‚æ•°
   */
  private createParamsFromSchema(userInput: string, schema: any): any {
    const params: any = {};
    
    if (schema.properties) {
      for (const [key, value] of Object.entries(schema.properties)) {
        const fieldSchema = value as any;
        
        // å¯¹äºå­—ç¬¦ä¸²ç±»å‹å‚æ•°ï¼Œå°è¯•ä»ç”¨æˆ·è¾“å…¥ä¸­æå–
        if (fieldSchema.type === 'string') {
          if (key.toLowerCase().includes('protocol') || key.toLowerCase().includes('name')) {
            // å°è¯•ä»ç”¨æˆ·è¾“å…¥ä¸­æå–åè®®åç§°
            const protocolMatch = userInput.match(/\b([A-Za-z][A-Za-z0-9\s]*)\s+protocol/i);
            if (protocolMatch) {
              params[key] = protocolMatch[1].trim();
            } else {
              // ä»ç”¨æˆ·è¾“å…¥ä¸­æå–ç¬¬ä¸€ä¸ªå¤§å†™å¼€å¤´çš„å•è¯ä½œä¸ºåè®®å
              const nameMatch = userInput.match(/\b([A-Z][a-z]+)/);
              if (nameMatch) {
                params[key] = nameMatch[1];
              } else {
                params[key] = userInput.split(' ')[0]; // ä½¿ç”¨ç¬¬ä¸€ä¸ªå•è¯ä½œä¸ºé™çº§
              }
            }
          } else {
            params[key] = userInput; // é»˜è®¤ä½¿ç”¨æ•´ä¸ªç”¨æˆ·è¾“å…¥
          }
        } else if (fieldSchema.type === 'number' || fieldSchema.type === 'integer') {
          params[key] = 1; // é»˜è®¤æ•°å€¼
        } else if (fieldSchema.type === 'boolean') {
          params[key] = true; // é»˜è®¤å¸ƒå°”å€¼
        } else {
          params[key] = userInput; // é»˜è®¤ä½¿ç”¨ç”¨æˆ·è¾“å…¥
        }
      }
    }
    
    return params;
  }

  /**
   * é€šè¿‡LangChainè°ƒç”¨MCPå·¥å…·
   */
  private async callMCPToolWithLangChain(mcpName: string, toolName: string, input: any, taskId?: string): Promise<any> {
    try {
      // ğŸ”§ æ–°å¢ï¼šè®°å½•å†…å­˜ä½¿ç”¨æƒ…å†µå’Œè¾“å…¥æ•°æ®å¤§å°
      const memUsageBefore = process.memoryUsage();
      const inputSize = JSON.stringify(input).length;
      
      logger.info(`ğŸ” Calling MCP tool via LangChain [MCP: ${mcpName}, Tool: ${toolName}]`);
      
      // è·å–ç”¨æˆ·ID
      let userId: string | undefined;
      if (taskId) {
        const task = await taskService.getTaskById(taskId);
        userId = task?.userId;
      }
      
      // éªŒè¯å¹¶ç¡®ä¿å®¢æˆ·ç«¯è¿æ¥æ­£å¸¸
      await this.ensureClientConnection(mcpName, userId);
      
      // è·å–MCPçš„æ‰€æœ‰å·¥å…·
      const mcpTools = await this.mcpManager.getTools(mcpName, userId);
      
      // æŸ¥æ‰¾ç›®æ ‡å·¥å…· - å¤„ç†è¿å­—ç¬¦å’Œä¸‹åˆ’çº¿çš„å…¼å®¹æ€§
      const targetTool = mcpTools.find(t => 
        t.name === toolName || 
        t.name.replace(/-/g, '_') === toolName.replace(/-/g, '_') ||
        t.name.replace(/_/g, '-') === toolName.replace(/_/g, '-')
      );
      
      if (!targetTool) {
        logger.error(`Tool ${toolName} does not exist in MCP ${mcpName}`);
        logger.info(`Available tools: ${mcpTools.map(t => t.name).join(', ')}`);
        throw new Error(`Tool ${toolName} does not exist in MCP ${mcpName}`);
      }
      
      // å°†MCPå·¥å…·è½¬æ¢ä¸ºLangChainå·¥å…·
      const langchainTool = await this.mcpToolAdapter.convertMCPToolToLangChainTool(mcpName, targetTool, userId);
      
      // è°ƒç”¨LangChainå·¥å…·
      logger.info(`ğŸ“ Calling LangChain tool: ${langchainTool.name}`);
      logger.info(`ğŸ“¥ Input parameters: ${JSON.stringify(input, null, 2)}`);
      
      console.log(`\n==== LangChain Tool Call Details ====`);
      console.log(`Time: ${new Date().toISOString()}`);
      console.log(`MCP Name: ${mcpName}`);
      console.log(`Tool Name: ${toolName}`);
      console.log(`LangChain Tool Name: ${langchainTool.name}`);
      console.log(`Input Parameters to LangChain: ${JSON.stringify(input, null, 2)}`);
      console.log(`Tool Description: ${targetTool.description || 'No description'}`);
      console.log(`Tool Input Schema: ${JSON.stringify(targetTool.inputSchema, null, 2)}`);
      
      let result;
      try {
        // ğŸ”§ æ–°å¢ï¼šè®°å½•å·¥å…·è°ƒç”¨å‰çš„å†…å­˜çŠ¶æ€
        const memBeforeToolCall = process.memoryUsage();
        console.log(`\n==== ğŸ”§ Memory Before Tool Invoke ====`);
        console.log(`  RSS: ${(memBeforeToolCall.rss / 1024 / 1024).toFixed(2)} MB`);
        console.log(`  Heap Used: ${(memBeforeToolCall.heapUsed / 1024 / 1024).toFixed(2)} MB`);
        console.log(`  Heap Total: ${(memBeforeToolCall.heapTotal / 1024 / 1024).toFixed(2)} MB`);
        
        console.log(`ğŸš€ INVOKING LANGCHAIN TOOL: ${langchainTool.name}...`);
        result = await langchainTool.invoke(input);
        console.log(`âœ… LANGCHAIN TOOL INVOCATION COMPLETED`);
        
        // ğŸ”§ æ–°å¢ï¼šè®°å½•å·¥å…·è°ƒç”¨åçš„å†…å­˜çŠ¶æ€å’Œç»“æœå¤§å°
        const memAfterToolCall = process.memoryUsage();
        const resultSize = typeof result === 'string' ? result.length : JSON.stringify(result).length;
        
        console.log(`\n==== ğŸ§  Memory & Data Debug - AFTER Tool Invoke ====`);
        console.log(`  RSS: ${(memAfterToolCall.rss / 1024 / 1024).toFixed(2)} MB (${((memAfterToolCall.rss - memBeforeToolCall.rss) / 1024 / 1024).toFixed(2)} MB delta)`);
        console.log(`  Heap Used: ${(memAfterToolCall.heapUsed / 1024 / 1024).toFixed(2)} MB (${((memAfterToolCall.heapUsed - memBeforeToolCall.heapUsed) / 1024 / 1024).toFixed(2)} MB delta)`);
        console.log(`  Heap Total: ${(memAfterToolCall.heapTotal / 1024 / 1024).toFixed(2)} MB (${((memAfterToolCall.heapTotal - memBeforeToolCall.heapTotal) / 1024 / 1024).toFixed(2)} MB delta)`);
        console.log(`Result Data Size: ${resultSize} bytes (${(resultSize / 1024).toFixed(2)} KB, ${(resultSize / 1024 / 1024).toFixed(2)} MB)`);
        console.log(`Result Type: ${typeof result}`);
        console.log(`Result Preview: ${typeof result === 'string' ? result.substring(0, 500) : JSON.stringify(result).substring(0, 500)}...`);
        
      } catch (schemaError) {
        if (schemaError instanceof Error && schemaError.message && schemaError.message.includes('schema')) {
          logger.warn(`Schema validation failed, attempting to convert input parameters...`);
          console.log(`âš ï¸ Schema validation failed, attempting parameter conversion...`);
          console.log(`âš ï¸ Schema Error Details: ${schemaError.message}`);
          console.log(`âš ï¸ Schema Error Stack: ${schemaError.stack}`);
          
          // ä½¿ç”¨LLMè½¬æ¢è¾“å…¥å‚æ•°
          const conversionPrompt = `Convert the input parameters to match the tool schema.

Tool: ${targetTool.name}
Description: ${targetTool.description || 'No description'}
Expected Schema: ${JSON.stringify(targetTool.inputSchema, null, 2)}
Current Input: ${JSON.stringify(input, null, 2)}

Please respond with ONLY a valid JSON object that matches the expected schema.
For cryptocurrency tools:
- Use lowercase coin IDs like "bitcoin", "ethereum"
- Use "usd" for vs_currency
- Include boolean flags like include_market_cap: true, include_24hr_change: true`;

          const conversionResponse = await this.llm.invoke([
            new SystemMessage(conversionPrompt)
          ]);

          try {
            // ğŸ”§ æ”¹è¿›JSONè§£æï¼Œå…ˆæ¸…ç†LLMå“åº”ä¸­çš„é¢å¤–å†…å®¹
            let responseText = conversionResponse.content.toString().trim();
            
            console.log(`\n==== ğŸ“ LLM Parameter Conversion Debug ====`);
            console.log(`Raw LLM Response Length: ${responseText.length} chars`);
            console.log(`Raw LLM Response: ${responseText}`);
            
            // ç§»é™¤Markdownä»£ç å—æ ‡è®°
            responseText = responseText.replace(/```json\n?/g, '').replace(/```\n?/g, '');
            console.log(`After Markdown Cleanup: ${responseText}`);
            
            // å°è¯•æå–JSONå¯¹è±¡
            const jsonMatch = responseText.match(/\{[\s\S]*\}/);
            if (jsonMatch) {
              responseText = jsonMatch[0];
              console.log(`After JSON Extraction: ${responseText}`);
            }
            
            console.log(`ğŸ§¹ Final Cleaned LLM response: ${responseText}`);
            
            const convertedInput = JSON.parse(responseText);
            console.log(`ğŸ”„ Converted input: ${JSON.stringify(convertedInput, null, 2)}`);
            console.log(`ğŸ”„ Converted input size: ${JSON.stringify(convertedInput).length} bytes`);
            logger.info(`ğŸ”„ Attempting tool call with converted input: ${JSON.stringify(convertedInput)}`);
            
            // ğŸ”§ æ–°å¢ï¼šè®°å½•å‚æ•°è½¬æ¢åçš„å·¥å…·è°ƒç”¨
            const memBeforeConvertedCall = process.memoryUsage();
            console.log(`\n==== ğŸ”§ Memory Before Converted Tool Call ====`);
            console.log(`  RSS: ${(memBeforeConvertedCall.rss / 1024 / 1024).toFixed(2)} MB`);
            console.log(`  Heap Used: ${(memBeforeConvertedCall.heapUsed / 1024 / 1024).toFixed(2)} MB`);
            
            console.log(`ğŸš€ INVOKING LANGCHAIN TOOL WITH CONVERTED PARAMS: ${langchainTool.name}...`);
            result = await langchainTool.invoke(convertedInput);
            console.log(`âœ… CONVERTED TOOL CALL SUCCEEDED`);
            
            // ğŸ”§ æ–°å¢ï¼šè®°å½•è½¬æ¢åè°ƒç”¨çš„å†…å­˜çŠ¶æ€
            const memAfterConvertedCall = process.memoryUsage();
            const convertedResultSize = typeof result === 'string' ? result.length : JSON.stringify(result).length;
            
            console.log(`\n==== ğŸ§  Memory After Converted Tool Call ====`);
            console.log(`  RSS: ${(memAfterConvertedCall.rss / 1024 / 1024).toFixed(2)} MB (${((memAfterConvertedCall.rss - memBeforeConvertedCall.rss) / 1024 / 1024).toFixed(2)} MB delta)`);
            console.log(`  Heap Used: ${(memAfterConvertedCall.heapUsed / 1024 / 1024).toFixed(2)} MB (${((memAfterConvertedCall.heapUsed - memBeforeConvertedCall.heapUsed) / 1024 / 1024).toFixed(2)} MB delta)`);
            console.log(`Converted Result Size: ${convertedResultSize} bytes (${(convertedResultSize / 1024).toFixed(2)} KB, ${(convertedResultSize / 1024 / 1024).toFixed(2)} MB)`);
            
          } catch (conversionError) {
            console.log(`\n==== âŒ Parameter Conversion Error ====`);
            console.log(`Conversion Error: ${conversionError}`);
            console.log(`Conversion Error Message: ${conversionError instanceof Error ? conversionError.message : String(conversionError)}`);
            console.log(`Conversion Error Stack: ${conversionError instanceof Error ? conversionError.stack : 'No stack'}`);
            logger.error(`âŒ Parameter conversion failed: ${conversionError}`);
            logger.error(`âŒ Raw LLM response: ${conversionResponse.content.toString()}`);
            
            // ğŸ”§ æ·»åŠ æ›´æ™ºèƒ½çš„é™çº§å¤„ç†
            if (input && typeof input === 'string' && targetTool.inputSchema) {
              try {
                // å°è¯•æ ¹æ® schema è‡ªåŠ¨åˆ›å»ºå‚æ•°
                const autoParams = this.createParamsFromSchema(input, targetTool.inputSchema);
                console.log(`ğŸš¨ Attempting auto-generated params: ${JSON.stringify(autoParams, null, 2)}`);
                console.log(`ğŸš¨ Auto-generated params size: ${JSON.stringify(autoParams).length} bytes`);
                
                const memBeforeAutoCall = process.memoryUsage();
                console.log(`ğŸ”§ Memory Before Auto-Param Call: Heap Used ${(memBeforeAutoCall.heapUsed / 1024 / 1024).toFixed(2)} MB`);
                
                result = await langchainTool.invoke(autoParams);
                console.log(`âœ… Tool call succeeded with auto-generated params`);
                
                const memAfterAutoCall = process.memoryUsage();
                console.log(`ğŸ”§ Memory After Auto-Param Call: Heap Used ${(memAfterAutoCall.heapUsed / 1024 / 1024).toFixed(2)} MB (${((memAfterAutoCall.heapUsed - memBeforeAutoCall.heapUsed) / 1024 / 1024).toFixed(2)} MB delta)`);
                
              } catch (autoError) {
                console.log(`âŒ Auto-generated params failed: ${autoError}`);
                logger.error(`âŒ Auto-generated params also failed: ${autoError}`);
                throw schemaError; // æŠ›å‡ºåŸå§‹é”™è¯¯
              }
            } else {
              throw schemaError; // æŠ›å‡ºåŸå§‹é”™è¯¯
            }
          }
        } else {
          console.log(`âŒ Non-schema error: ${schemaError}`);
          throw schemaError;
        }
      }
      
      // ğŸ”§ æ–°å¢ï¼šè®°å½•æœ€ç»ˆç»“æœå¤„ç†å‰çš„çŠ¶æ€
      const memBeforeResultProcessing = process.memoryUsage();
      console.log(`\n==== ğŸ”§ Memory Before Result Processing ====`);
      console.log(`  RSS: ${(memBeforeResultProcessing.rss / 1024 / 1024).toFixed(2)} MB`);
      console.log(`  Heap Used: ${(memBeforeResultProcessing.heapUsed / 1024 / 1024).toFixed(2)} MB`);
      
      console.log(`\n==== LangChain Tool Call Raw Result ====`);
      console.log(`Raw Result Type: ${typeof result}`);
      console.log(`Raw Result Size: ${typeof result === 'string' ? result.length : JSON.stringify(result).length} bytes`);
      console.log(`Raw Result Preview: ${typeof result === 'string' ? result.substring(0, 1000) : JSON.stringify(result).substring(0, 1000)}...`);
      
      logger.info(`âœ… LangChain tool call successful`);
      logger.info(`ğŸ“¤ Raw result: ${typeof result === 'string' ? result.substring(0, 200) : JSON.stringify(result).substring(0, 200)}...`);
      
      // å°è¯•è§£æJSONç»“æœ
      let finalResult;
      try {
        console.log(`\n==== ğŸ“Š JSON Result Processing Debug ====`);
        console.log(`Starting JSON.parse() on result...`);
        console.log(`Result to parse (first 500 chars): ${typeof result === 'string' ? result.substring(0, 500) : JSON.stringify(result).substring(0, 500)}...`);
        
        // ğŸ”§ æ–°å¢ï¼šè®°å½•JSONè§£æå‰çš„å†…å­˜
        const memBeforeJSONParse = process.memoryUsage();
        console.log(`Memory before JSON.parse(): Heap Used ${(memBeforeJSONParse.heapUsed / 1024 / 1024).toFixed(2)} MB`);
        
        const parsedResult = JSON.parse(result);
        
        // ğŸ”§ æ–°å¢ï¼šè®°å½•JSONè§£æåçš„å†…å­˜
        const memAfterJSONParse = process.memoryUsage();
        console.log(`Memory after JSON.parse(): Heap Used ${(memAfterJSONParse.heapUsed / 1024 / 1024).toFixed(2)} MB (${((memAfterJSONParse.heapUsed - memBeforeJSONParse.heapUsed) / 1024 / 1024).toFixed(2)} MB delta)`);
        
        console.log(`âœ… JSON.parse() successful`);
        console.log(`Parsed result type: ${typeof parsedResult}`);
        console.log(`Parsed result keys: ${typeof parsedResult === 'object' && parsedResult !== null ? Object.keys(parsedResult) : 'Not an object'}`);
        
        if (parsedResult.content) {
          console.log(`Found content field in parsed result`);
          console.log(`Content type: ${typeof parsedResult.content}`);
          console.log(`Content size: ${JSON.stringify(parsedResult.content).length} bytes`);
          finalResult = parsedResult;
        } else {
          console.log(`No content field found, wrapping result`);
          finalResult = {
            content: [{
              type: 'text',
              text: result
            }]
          };
        }
      } catch (parseError) {
        console.log(`âŒ JSON.parse() failed: ${parseError}`);
        console.log(`Parse error message: ${parseError instanceof Error ? parseError.message : String(parseError)}`);
        console.log(`Creating wrapped result...`);
        finalResult = {
          content: [{
            type: 'text',
            text: result
          }]
        };
      }
      
      // ğŸ”§ æ–°å¢ï¼šè®°å½•å¤„ç†å®Œæˆåçš„æœ€ç»ˆå†…å­˜çŠ¶æ€
      const memUsageAfter = process.memoryUsage();
      const finalResultSize = JSON.stringify(finalResult).length;
      
      console.log(`\n==== ğŸ§  Memory & Data Debug - FINAL STATE ====`);
      console.log(`Memory After (MB):`);
      console.log(`  RSS: ${(memUsageAfter.rss / 1024 / 1024).toFixed(2)} (${((memUsageAfter.rss - memUsageBefore.rss) / 1024 / 1024).toFixed(2)} MB total delta)`);
      console.log(`  Heap Used: ${(memUsageAfter.heapUsed / 1024 / 1024).toFixed(2)} (${((memUsageAfter.heapUsed - memUsageBefore.heapUsed) / 1024 / 1024).toFixed(2)} MB total delta)`);
      console.log(`  Heap Total: ${(memUsageAfter.heapTotal / 1024 / 1024).toFixed(2)} (${((memUsageAfter.heapTotal - memUsageBefore.heapTotal) / 1024 / 1024).toFixed(2)} MB total delta)`);
      console.log(`  External: ${(memUsageAfter.external / 1024 / 1024).toFixed(2)} (${((memUsageAfter.external - memUsageBefore.external) / 1024 / 1024).toFixed(2)} MB total delta)`);
      console.log(`Final Result Size: ${finalResultSize} bytes (${(finalResultSize / 1024).toFixed(2)} KB, ${(finalResultSize / 1024 / 1024).toFixed(2)} MB)`);
      console.log(`ğŸ¯ MEMORY EFFICIENCY RATIO: ${((finalResultSize / 1024 / 1024) / ((memUsageAfter.heapUsed - memUsageBefore.heapUsed) / 1024 / 1024)).toFixed(2)} (result MB / heap delta MB)`);
      
      // ğŸ”§ å¼ºåˆ¶åƒåœ¾å›æ”¶ï¼ˆå¦‚æœå¯ç”¨ï¼‰
      if (global.gc) {
        console.log(`ğŸ—‘ï¸ Forcing garbage collection...`);
        global.gc();
        const memAfterGC = process.memoryUsage();
        console.log(`Memory after GC: Heap Used ${(memAfterGC.heapUsed / 1024 / 1024).toFixed(2)} MB (${((memAfterGC.heapUsed - memUsageAfter.heapUsed) / 1024 / 1024).toFixed(2)} MB freed)`);
      } else {
        console.log(`âš ï¸ Garbage collection not available (start Node.js with --expose-gc to enable)`);
      }
      
      // ğŸ”§ æ–°å¢ï¼šx-mcpè‡ªåŠ¨å‘å¸ƒå¤„ç†
      const processedResult = await this.handleXMcpAutoPublish(mcpName, toolName, finalResult, userId);
      
      return processedResult;
    } catch (error) {
      // ğŸ”§ æ–°å¢ï¼šè®°å½•é”™è¯¯æ—¶çš„å†…å­˜çŠ¶æ€
      const memUsageOnError = process.memoryUsage();
      console.log(`\n==== âŒ Memory Debug - ERROR STATE ====`);
      console.log(`Memory on Error (MB):`);
      console.log(`  RSS: ${(memUsageOnError.rss / 1024 / 1024).toFixed(2)}`);
      console.log(`  Heap Used: ${(memUsageOnError.heapUsed / 1024 / 1024).toFixed(2)}`);
      console.log(`  Heap Total: ${(memUsageOnError.heapTotal / 1024 / 1024).toFixed(2)}`);
      console.log(`Error Type: ${error instanceof Error ? error.constructor.name : typeof error}`);
      console.log(`Error Message: ${error instanceof Error ? error.message : String(error)}`);
      console.log(`Error Stack: ${error instanceof Error ? error.stack : 'No stack trace'}`);
      
      logger.error(`âŒ LangChain tool call failed:`, error);
      throw error;
    }
  }

  /**
   * æ ¹æ®ä»»åŠ¡ç›®æ ‡åŠ¨æ€è°ƒç”¨MCPå·¥å…·
   */
  private async callMCPWithObjective(mcpName: string, objective: string, input: any, taskId?: string): Promise<any> {
    try {
      logger.info(`ğŸ¯ Calling MCP with objective [MCP: ${mcpName}, Objective: ${objective}]`);
      logger.info(`ğŸ“¥ Input parameters: ${JSON.stringify(input, null, 2)}`);

      // æ ‡å‡†åŒ–MCPåç§°
      const actualMcpName = this.normalizeMCPName(mcpName);
      if (actualMcpName !== mcpName) {
        logger.info(`MCP name mapping: '${mcpName}' mapped to '${actualMcpName}'`);
      }

      // è·å–ç”¨æˆ·ID
      let userId: string | undefined;
      if (taskId) {
        const task = await taskService.getTaskById(taskId);
        userId = task?.userId;
      }

      // æ£€æŸ¥MCPæ˜¯å¦å·²è¿æ¥
      const connectedMCPs = this.mcpManager.getConnectedMCPs(userId);
      const isConnected = connectedMCPs.some(mcp => mcp.name === actualMcpName);
      
      console.log(`\n==== MCP Connection Status Debug ====`);
      console.log(`MCP Name: ${actualMcpName}`);
      console.log(`User ID: ${userId}`);
      console.log(`Is Connected: ${isConnected}`);
      console.log(`Connected MCPs:`, connectedMCPs.map(mcp => ({
        name: mcp.name,
        env: mcp.env,
        connected: mcp.connected
      })));
      
      // æ£€æŸ¥å·²è¿æ¥çš„MCPæ˜¯å¦æœ‰æ­£ç¡®çš„è®¤è¯ä¿¡æ¯
      let needsReconnection = false;
      if (isConnected) {
        const connectedMcp = connectedMCPs.find(mcp => mcp.name === actualMcpName);
        if (connectedMcp) {
          console.log(`Connected MCP env:`, connectedMcp.env);
          const apiKey = connectedMcp.env?.COINMARKETCAP_API_KEY;
          console.log(`API Key status: ${apiKey ? 'Present' : 'Missing'} (length: ${apiKey?.length || 0})`);
          
          // å¦‚æœAPIå¯†é’¥ç¼ºå¤±ï¼Œéœ€è¦é‡æ–°è¿æ¥
          if (!apiKey || apiKey === '') {
            console.log(`API Key missing, need to reconnect with proper authentication`);
            needsReconnection = true;
          }
        }
      }
      
      // å¦‚æœæœªè¿æ¥æˆ–éœ€è¦é‡æ–°è¿æ¥ï¼Œå°è¯•è‡ªåŠ¨è¿æ¥
      if (!isConnected || needsReconnection) {
        if (needsReconnection) {
          console.log(`Disconnecting MCP ${actualMcpName} to reconnect with proper auth...`);
          await this.mcpManager.disconnect(actualMcpName, userId);
        }
        console.log(`Calling autoConnectMCP with task ID: ${taskId}...`);
        await this.autoConnectMCP(actualMcpName, taskId, userId);
      } else {
        console.log(`MCP already connected with valid auth, skipping autoConnectMCP`);
      }

      // è·å–MCPçš„æ‰€æœ‰å·¥å…·
      const mcpTools = await this.mcpManager.getTools(actualMcpName, userId);
      logger.info(`ğŸ“‹ Available tools in ${actualMcpName}: ${mcpTools.map(t => t.name).join(', ')}`);

      // ä½¿ç”¨LLMæ ¹æ®ç›®æ ‡é€‰æ‹©åˆé€‚çš„å·¥å…·ï¼Œå¹¶è½¬æ¢è¾“å…¥å‚æ•°
      const toolSelectionPrompt = `You are an expert data transformation assistant. Your task is to intelligently transform the output from one tool into the appropriate input for the next tool in a workflow chain.

CONTEXT:
- Previous step output: ${typeof input === 'string' ? input : JSON.stringify(input, null, 2)}
- Next action: ${objective}
- Available tools with their schemas:
${mcpTools.map(tool => {
  const schema = tool.inputSchema || {};
  return `
Tool: ${tool.name}
Description: ${tool.description || 'No description'}
Input Schema: ${JSON.stringify(schema, null, 2)}
`;
}).join('\n')}

TRANSFORMATION PRINCIPLES:
1. **Select the correct tool**: Choose the most appropriate tool from available options based on the objective
2. **Transform parameters**: Convert previous output into correct input format for the selected tool
3. **CRITICAL: Use exact parameter names from the schema**: 
   - ALWAYS check the inputSchema and use the exact parameter names shown
   - For example, if the schema shows "text" as parameter name, use "text" NOT "tweet" or other variations
   - Match the exact property names shown in the inputSchema
4. **Handle missing data intelligently**: 
   - CRITICAL: NEVER use placeholders or descriptions - always extract ACTUAL DATA
   - For required data: Find and extract the real content from the input or previous results
   - If actual data exists: Use it directly, never summarize or describe it
   - If data is truly missing: Return empty string or null, never use descriptive text
   - For optional fields: Omit them if not relevant
   - DO NOT use hardcoded examples, templates, or placeholder descriptions

5. **Format according to tool expectations**:
   - Social media tools: Create engaging, concise content from the data
   - API tools: Return structured JSON exactly matching the API schema
   - Content tools: Transform data into readable, formatted text
   - Search tools: Extract relevant keywords or criteria

CRITICAL TWITTER RULES:
- Twitter has a HARD 280 character limit!
- Count ALL characters including spaces, emojis, URLs, hashtags
- If content is too long, you MUST:
  1. Use abbreviations (e.g., "w/" for "with")
  2. Shorten usernames (e.g., "@user" instead of full names)
  3. Remove less important details
  4. Keep URLs whenever possible as they are valuable references
  5. If URLs must be removed due to length, prefer keeping the most important ones
- For threads: First tweet should be <250 chars to leave room for thread numbering
- PRIORITY: Always try to include original tweet URLs when space allows
- Example of good tweet: "ğŸš€ Top 3 Meme Coins ğŸ§µ\n\n1ï¸âƒ£ Big Papa ($PAPA) - Solana meme coin\n2ï¸âƒ£ $BEAST - Pulsechain revolution\n3ï¸âƒ£ Novus Ordo ($NOVO) - Providence themed\n\n#MemeCoins #Crypto" (under 280 chars)

IMPORTANT REMINDERS:
- Base transformations on actual data and tool schemas, not examples
- Each tool has unique requirements - analyze the schema carefully
- Focus on the objective and what the tool actually needs
- VERIFY character count for Twitter - must be under 280!

OUTPUT FORMAT:
Return a JSON object with exactly this structure:
{
  "toolName": "exact_tool_name_from_available_tools",
  "inputParams": { /* transformed parameters using EXACT parameter names from the tool's input schema */ },
  "reasoning": "brief explanation of tool selection and parameter transformation"
}

EXAMPLE TRANSFORMATIONS:
- For create_tweet tool with schema {"text": {"type": "string"}}: 
  * Use {"text": "your tweet content"} NOT {"tweet": "content"}
  * MUST be under 280 characters! Summarize if needed
  * For threads: Create first tweet mentioning "Thread 1/n ğŸ§µ"
- For cryptocurrency queries: Use proper coin IDs like "bitcoin", "ethereum" and "usd" for vs_currency
- For social media: Extract key insights and format as engaging content (respect character limits!)
- For API calls: Structure data according to API schema requirements
- For content creation: Transform data into readable, formatted text

CRITICAL CONTENT EXTRACTION:
- When previous step results contain actual content: EXTRACT THE REAL TEXT, never use placeholders
- Example: If previous contains "Summary: Bitcoin is trending up 5%" â†’ use "Bitcoin is trending up 5%"
- NEVER use "[Insert Data Here]" or "Latest data from Dune for queryId X" - extract actual content!
- ALWAYS extract and include actual data/URLs/links when available in the source data
- If no actual data exists, return empty/null, never use descriptive placeholders

IMPORTANT: Always check the exact parameter names in the inputSchema and use those exact names in your inputParams.

Transform the data now:`;

      const toolSelectionResponse = await this.llm.invoke([
        new SystemMessage(toolSelectionPrompt)
      ]);

      let toolSelection;
      try {
        toolSelection = this.parseLLMJsonResponse(toolSelectionResponse.content.toString());
      } catch (parseError) {
        const errorMessage = parseError instanceof Error ? parseError.message : String(parseError);
        logger.error(`Failed to parse tool selection response: ${errorMessage}`);
        
        // å›é€€åˆ°ç®€å•çš„å·¥å…·é€‰æ‹©
        const fallbackPrompt = `Available tools: ${mcpTools.map(t => t.name).join(', ')}\nObjective: ${objective}\nSelect ONLY the exact tool name:`;
        const fallbackResponse = await this.llm.invoke([new SystemMessage(fallbackPrompt)]);
        const fallbackToolName = fallbackResponse.content.toString().trim();
        toolSelection = {
          toolName: fallbackToolName,
          inputParams: input,
          reasoning: "Fallback selection due to parsing error"
        };
      }

      const selectedToolName = toolSelection.toolName;
      const llmConvertedInput = toolSelection.inputParams || input;
      
      // ğŸ”§ æ–°å¢ï¼šè¿›ä¸€æ­¥éªŒè¯å’Œè½¬æ¢å‚æ•°åï¼Œç¡®ä¿ä¸ schema åŒ¹é…
      const targetTool = mcpTools.find(t => t.name === selectedToolName);
      const finalConvertedInput = targetTool ? this.validateParameterNames(llmConvertedInput, targetTool.inputSchema) : llmConvertedInput;
      
      logger.info(`ğŸ”§ LLM selected tool: ${selectedToolName}`);
      logger.info(`ğŸ”§ LLM converted input: ${JSON.stringify(llmConvertedInput)}`);
      logger.info(`ğŸ”§ Final validated input: ${JSON.stringify(finalConvertedInput)}`);
      logger.info(`ğŸ§  Selection reasoning: ${toolSelection.reasoning || 'No reasoning provided'}`);

      // éªŒè¯é€‰æ‹©çš„å·¥å…·æ˜¯å¦å­˜åœ¨
      let selectedTool = mcpTools.find(t => t.name === selectedToolName);
      let finalToolName = selectedToolName;
      
      if (!selectedTool) {
        logger.error(`Selected tool ${selectedToolName} not found in available tools`);
        // å°è¯•æ¨¡ç³ŠåŒ¹é…
        const fuzzyMatch = mcpTools.find(t => 
          t.name.toLowerCase().includes(selectedToolName.toLowerCase()) ||
          selectedToolName.toLowerCase().includes(t.name.toLowerCase())
        );
        if (fuzzyMatch) {
          logger.info(`Found fuzzy match: ${fuzzyMatch.name}`);
          selectedTool = fuzzyMatch;
          finalToolName = fuzzyMatch.name;
        } else {
          throw new Error(`Tool selection failed: ${selectedToolName} not found in available tools`);
        }
      }

      // è°ƒç”¨é€‰å®šçš„å·¥å…·
      console.log(`\n==== MCP Objective-Based Call Details ====`);
      console.log(`Time: ${new Date().toISOString()}`);
      console.log(`Original MCP Name: ${mcpName}`);
      console.log(`Actual MCP Name: ${actualMcpName}`);
      console.log(`Objective: ${objective}`);
      console.log(`Selected Tool: ${finalToolName}`);
      console.log(`Original Input: ${JSON.stringify(input, null, 2)}`);
      console.log(`Converted Input Parameters: ${JSON.stringify(finalConvertedInput, null, 2)}`);
      
      const result = await this.callMCPToolWithLangChain(actualMcpName, finalToolName, finalConvertedInput, taskId);
      
      console.log(`\n==== MCP Objective-Based Call Result ====`);
      console.log(`Status: Success`);
      console.log(`Return Data: ${JSON.stringify(result, null, 2)}`);
      
      return result;

    } catch (error) {
      logger.error(`âŒ MCP objective-based call failed [${mcpName}/${objective}]:`, error);
      throw error;
    }
  }

  /**
   * é€šç”¨MCPå·¥å…·è°ƒç”¨æ–¹æ³•
   */
  private async callMCPTool(mcpName: string, toolNameOrObjective: string, input: any, taskId?: string): Promise<any> {
    try {
      // åˆ¤æ–­æ˜¯å·¥å…·åè¿˜æ˜¯ä»»åŠ¡ç›®æ ‡
      // å¦‚æœåŒ…å«ç©ºæ ¼æˆ–ä¸­æ–‡ï¼Œå¾ˆå¯èƒ½æ˜¯ä»»åŠ¡ç›®æ ‡æè¿°
      const isObjective = /[\s\u4e00-\u9fa5]/.test(toolNameOrObjective) || 
                         toolNameOrObjective.includes('_') === false && 
                         toolNameOrObjective.length > 30;

      if (isObjective) {
        logger.info(`ğŸ¯ Detected objective-based call: ${toolNameOrObjective}`);
        return await this.callMCPWithObjective(mcpName, toolNameOrObjective, input, taskId);
      } else {
        logger.info(`ğŸ”§ Detected tool-based call: ${toolNameOrObjective}`);
        // åŸæœ‰çš„ç›´æ¥è°ƒç”¨å·¥å…·çš„é€»è¾‘
        logger.info(`ğŸ” Calling MCP tool [MCP: ${mcpName}, Tool: ${toolNameOrObjective}]`);
        logger.info(`ğŸ“¥ MCP tool input parameters: ${JSON.stringify(input, null, 2)}`);

        console.log(`\n==== MCP Call Details ====`);
        console.log(`Time: ${new Date().toISOString()}`);
        console.log(`MCP Service: ${mcpName}`);
        console.log(`Tool Name: ${toolNameOrObjective}`);
        console.log(`Input Parameters: ${JSON.stringify(input, null, 2)}`);
        
        // æ ‡å‡†åŒ–MCPåç§°
        const actualMcpName = this.normalizeMCPName(mcpName);
        if (actualMcpName !== mcpName) {
          logger.info(`MCP name mapping: '${mcpName}' mapped to '${actualMcpName}'`);
        }

        // æ£€æŸ¥MCPæ˜¯å¦å·²è¿æ¥
        const connectedMCPs = this.mcpManager.getConnectedMCPs();
        const isConnected = connectedMCPs.some(mcp => mcp.name === actualMcpName);
        
        // å¦‚æœæœªè¿æ¥ï¼Œå°è¯•è‡ªåŠ¨è¿æ¥
        if (!isConnected) {
          await this.autoConnectMCP(actualMcpName, taskId);
        }

        // ä½¿ç”¨LangChainè°ƒç”¨MCPå·¥å…·
        logger.info(`ğŸ”— Using LangChain to call MCP tool...`);
        const result = await this.callMCPToolWithLangChain(actualMcpName, toolNameOrObjective, input, taskId);

        console.log(`\n==== MCP Call Result (via LangChain) ====`);
        console.log(`Status: Success`);
        console.log(`Return Data: ${JSON.stringify(result, null, 2)}`);

        logger.info(`ğŸ“¤ MCP tool return result (LangChain): ${JSON.stringify(result, null, 2)}`);
        logger.info(`âœ… MCP tool call successful (via LangChain) [MCP: ${mcpName}, Tool: ${toolNameOrObjective}]`);
        
        return result;
      }
    } catch (error) {
      console.log(`\n==== MCP Call Error ====`);
      console.log(`Status: Failed`);
      console.log(`Error Message: ${error instanceof Error ? error.message : String(error)}`);
      console.log(`Error Details: ${JSON.stringify(error, null, 2)}`);

      logger.error(`âŒ MCP tool call failed [${mcpName}/${toolNameOrObjective}]:`, error);
      throw error;
    }
  }
  
  /**
   * è‡ªåŠ¨è¿æ¥MCPæœåŠ¡
   */
  private async autoConnectMCP(mcpName: string, taskId?: string, userId?: string): Promise<void> {
    logger.info(`MCP ${mcpName} not connected, attempting auto-connection...`);
    
    // ä»predefinedMCPsè·å–MCPé…ç½®
    const { getPredefinedMCP } = await import('./predefinedMCPs.js');
    const mcpConfig = getPredefinedMCP(mcpName);
    
    if (!mcpConfig) {
      logger.error(`MCP ${mcpName} configuration not found`);
      throw new Error(`MCP ${mcpName} configuration not found`);
    }
    
    // åŠ¨æ€æ³¨å…¥ç”¨æˆ·è®¤è¯ä¿¡æ¯
    const dynamicEnv = await this.injectUserAuthentication(mcpConfig, taskId);
    
    // å¤„ç†argsä¸­çš„ç¯å¢ƒå˜é‡æ›¿æ¢
    const dynamicArgs = await this.injectArgsAuthentication(mcpConfig.args || [], dynamicEnv, taskId);
    
    // ä½¿ç”¨åŠ¨æ€ç¯å¢ƒå˜é‡å’Œargsåˆ›å»ºMCPé…ç½®
    const dynamicMcpConfig = {
      ...mcpConfig,
      env: dynamicEnv,
      args: dynamicArgs
    };
    
    // å°è¯•è¿æ¥MCPï¼Œä¼ é€’userId
    const connected = await this.mcpManager.connectPredefined(dynamicMcpConfig, userId);
    if (!connected) {
      throw new Error(`Failed to connect to MCP ${mcpName}. Please ensure the MCP server is installed and configured correctly.`);
    }
    
    logger.info(`âœ… MCP ${mcpName} auto-connection successful`);
    
    // éªŒè¯å·¥å…·æ˜¯å¦å­˜åœ¨å¹¶è¯¦ç»†è®°å½•
    try {
      const tools = await this.mcpManager.getTools(mcpName, userId);
      logger.info(`âœ… Available tools after connection [${mcpName}]: ${tools.map(t => t.name).join(', ')}`);
      
      // è¯¦ç»†è®°å½•æ¯ä¸ªå·¥å…·çš„ä¿¡æ¯
      tools.forEach((tool, index) => {
        logger.info(`ğŸ”§ Tool ${index + 1}: ${tool.name}`);
        logger.info(`   Description: ${tool.description || 'No description'}`);
        if (tool.inputSchema) {
          logger.info(`   Input Schema: ${JSON.stringify(tool.inputSchema, null, 2)}`);
        }
      });
      
    } catch (toolError) {
      logger.error(`âŒ Unable to get tool list for MCP ${mcpName}:`, toolError);
    }
  }
  
  /**
   * åŠ¨æ€æ³¨å…¥ç”¨æˆ·è®¤è¯ä¿¡æ¯
   */
  private async injectUserAuthentication(mcpConfig: any, taskId?: string): Promise<Record<string, string>> {
    let dynamicEnv = { ...mcpConfig.env };
    
    console.log(`\n==== Authentication Injection Debug ====`);
    console.log(`Time: ${new Date().toISOString()}`);
    console.log(`MCP Name: ${mcpConfig.name}`);
    console.log(`Task ID: ${taskId}`);
    console.log(`Original Env: ${JSON.stringify(mcpConfig.env, null, 2)}`);
    console.log(`Dynamic Env (initial): ${JSON.stringify(dynamicEnv, null, 2)}`);
    
    // æ£€æŸ¥æ˜¯å¦éœ€è¦è®¤è¯
    if (mcpConfig.env) {
      const missingEnvVars: string[] = [];
      
      // æ£€æŸ¥æ¯ä¸ªç¯å¢ƒå˜é‡æ˜¯å¦ç¼ºå¤±
      for (const [key, value] of Object.entries(mcpConfig.env)) {
        if (!value || value === '') {
          missingEnvVars.push(key);
        }
      }
      
      console.log(`Missing env vars: ${JSON.stringify(missingEnvVars)}`);
      
      // å¦‚æœæœ‰ç¼ºå¤±çš„ç¯å¢ƒå˜é‡ï¼Œå°è¯•ä»æ•°æ®åº“è·å–ç”¨æˆ·è®¤è¯ä¿¡æ¯
      if (missingEnvVars.length > 0 && taskId) {
        logger.info(`MCP needs authentication, attempting to get user auth data from database...`);
        
        try {
          const currentTask = await taskService.getTaskById(taskId);
          if (currentTask) {
            const userId = currentTask.userId;
            logger.info(`Got user ID from task context: ${userId}`);
            console.log(`User ID: ${userId}`);
            
            const userAuth = await this.mcpAuthService.getUserMCPAuth(userId, mcpConfig.name);
            console.log(`User Auth Result:`, {
              hasUserAuth: !!userAuth,
              isVerified: userAuth?.isVerified,
              hasAuthData: !!userAuth?.authData
            });
            
            if (userAuth && userAuth.isVerified && userAuth.authData) {
              logger.info(`Found user ${userId} auth info for ${mcpConfig.name}, injecting environment variables...`);
              console.log(`\nğŸ”§ === MCP Auth Injection Debug ===`);
              console.log(`MCP Name: ${mcpConfig.name}`);
              console.log(`User ID: ${userId}`);
              console.log(`Task ID: ${taskId}`);
              console.log(`Auth Data Keys: ${Object.keys(userAuth.authData)}`);
              console.log(`Auth Params: ${JSON.stringify(mcpConfig.authParams, null, 2)}`);
              console.log(`Env Config: ${JSON.stringify(mcpConfig.env, null, 2)}`);
              console.log(`User Auth Data: ${JSON.stringify(userAuth.authData, null, 2)}`);
              
              // åŠ¨æ€æ³¨å…¥è®¤è¯ä¿¡æ¯åˆ°ç¯å¢ƒå˜é‡
              for (const [envKey, envValue] of Object.entries(mcpConfig.env)) {
                console.log(`Checking env var: ${envKey} = "${envValue}"`);
                
                // ğŸ”§ æ”¹è¿›ï¼šæ£€æŸ¥ç”¨æˆ·è®¤è¯æ•°æ®ä¸­æ˜¯å¦æœ‰å¯¹åº”çš„é”®
                let authValue = userAuth.authData[envKey];
                
                // ğŸ”§ å¦‚æœç›´æ¥é”®åä¸å­˜åœ¨ï¼Œå°è¯•ä»authParamsæ˜ å°„ä¸­æŸ¥æ‰¾
                if (!authValue && mcpConfig.authParams && mcpConfig.authParams[envKey]) {
                  const authParamKey = mcpConfig.authParams[envKey];
                  authValue = userAuth.authData[authParamKey];
                  console.log(`ğŸ”§ Trying authParams mapping: ${envKey} -> ${authParamKey}, value: "${authValue}"`);
                }
                
                if ((!envValue || envValue === '') && authValue) {
                  // ğŸ”§ ç‰¹æ®Šå¤„ç†Notion MCPçš„OPENAPI_MCP_HEADERS
                  if (envKey === 'OPENAPI_MCP_HEADERS' && mcpConfig.name === 'notion-mcp') {
                    console.log(`ğŸ”§ å¤„ç†Notion MCPçš„OPENAPI_MCP_HEADERS: "${authValue}"`);
                    
                    // æ£€æŸ¥ç”¨æˆ·å¡«å†™çš„æ˜¯å¦å·²ç»æ˜¯å®Œæ•´çš„JSONå­—ç¬¦ä¸²
                    if (authValue.startsWith('{') && authValue.endsWith('}')) {
                      // ç”¨æˆ·å¡«å†™çš„æ˜¯å®Œæ•´JSONï¼Œç›´æ¥ä½¿ç”¨
                      dynamicEnv[envKey] = authValue;
                      console.log(`âœ… ä½¿ç”¨å®Œæ•´JSONæ ¼å¼: ${authValue}`);
                    } else if (authValue.startsWith('ntn_') || authValue.startsWith('secret_')) {
                      // ç”¨æˆ·åªå¡«å†™äº†tokenï¼Œæ„å»ºå®Œæ•´çš„JSONå­—ç¬¦ä¸²
                      const jsonHeaders = JSON.stringify({
                        "Authorization": `Bearer ${authValue}`,
                        "Notion-Version": "2022-06-28"
                      });
                      dynamicEnv[envKey] = jsonHeaders;
                      console.log(`âœ… è‡ªåŠ¨æ„å»ºJSONæ ¼å¼: ${jsonHeaders}`);
                      logger.info(`è‡ªåŠ¨æ„å»ºNotionè®¤è¯JSON: ${jsonHeaders}`);
                    } else {
                      // å°è¯•è§£æä¸ºJSONï¼Œå¦‚æœå¤±è´¥åˆ™å½“ä½œtokenå¤„ç†
                      try {
                        JSON.parse(authValue);
                        dynamicEnv[envKey] = authValue;
                        console.log(`âœ… éªŒè¯JSONæ ¼å¼æœ‰æ•ˆ: ${authValue}`);
                      } catch {
                        // å½“ä½œtokenå¤„ç†
                        const jsonHeaders = JSON.stringify({
                          "Authorization": `Bearer ${authValue}`,
                          "Notion-Version": "2022-06-28"
                        });
                        dynamicEnv[envKey] = jsonHeaders;
                        console.log(`âœ… è§£æå¤±è´¥ï¼Œå½“ä½œtokenå¤„ç†: ${jsonHeaders}`);
                      }
                    }
                  } else {
                    // å…¶ä»–MCPçš„æ­£å¸¸å¤„ç†
                    dynamicEnv[envKey] = authValue;
                    console.log(`âœ… Injected ${envKey} = "${authValue}"`);
                  }
                  logger.info(`Injected environment variable ${envKey}`);
                } else {
                  console.log(`âŒ Not injecting ${envKey}: envValue="${envValue}", authValue: "${authValue}"`);
                }
              }
              
              const stillMissingVars = missingEnvVars.filter(key => !dynamicEnv[key] || dynamicEnv[key] === '');
              if (stillMissingVars.length === 0) {
                logger.info(`âœ… Successfully injected all required auth info for ${mcpConfig.name}`);
                console.log(`âœ… All required auth info injected successfully`);
              } else {
                console.log(`âŒ Still missing vars: ${JSON.stringify(stillMissingVars)}`);
              }
            } else {
              console.log(`âŒ No valid user auth found:`, {
                hasUserAuth: !!userAuth,
                isVerified: userAuth?.isVerified,
                hasAuthData: !!userAuth?.authData
              });
            }
          } else {
            console.log(`âŒ Task not found: ${taskId}`);
          }
        } catch (error) {
          logger.error(`Failed to get user auth info:`, error);
          console.log(`âŒ Error getting user auth:`, error);
        }
      }
    }
    
    console.log(`Final Dynamic Env: ${JSON.stringify(dynamicEnv, null, 2)}`);
    return dynamicEnv;
  }
  
  /**
   * åŠ¨æ€æ³¨å…¥argsä¸­çš„è®¤è¯ä¿¡æ¯
   */
  private async injectArgsAuthentication(originalArgs: string[], dynamicEnv: Record<string, string>, taskId?: string): Promise<string[]> {
    if (!originalArgs || originalArgs.length === 0) {
      return originalArgs;
    }
    
    console.log(`\n==== Args Authentication Injection Debug ====`);
    console.log(`Time: ${new Date().toISOString()}`);
    console.log(`Task ID: ${taskId}`);
    console.log(`Original Args: ${JSON.stringify(originalArgs, null, 2)}`);
    console.log(`Dynamic Env: ${JSON.stringify(dynamicEnv, null, 2)}`);
    
    // åˆ›å»ºargsçš„å‰¯æœ¬è¿›è¡Œå¤„ç†
    const dynamicArgs = [...originalArgs];
    
    // éå†æ¯ä¸ªargï¼ŒæŸ¥æ‰¾å¹¶æ›¿æ¢ç¯å¢ƒå˜é‡å¼•ç”¨
    for (let i = 0; i < dynamicArgs.length; i++) {
      const arg = dynamicArgs[i];
      
      // æŸ¥æ‰¾åŒ…å« process.env.* çš„å‚æ•°
      if (typeof arg === 'string' && arg.includes('process.env.')) {
        console.log(`Processing arg ${i}: "${arg}"`);
        
        // ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æŸ¥æ‰¾æ‰€æœ‰çš„ process.env.VARIABLE_NAME å¼•ç”¨
        const envVarRegex = /process\.env\.([A-Z_][A-Z0-9_]*)/g;
        let modifiedArg = arg;
        let match;
        
        while ((match = envVarRegex.exec(arg)) !== null) {
          const envVarName = match[1]; // ç¯å¢ƒå˜é‡å
          const fullMatch = match[0]; // å®Œæ•´åŒ¹é…çš„å­—ç¬¦ä¸²
          
          console.log(`Found env var reference: ${fullMatch} (variable: ${envVarName})`);
          
          // å…ˆæ£€æŸ¥dynamicEnvä¸­æ˜¯å¦æœ‰å€¼
          if (dynamicEnv[envVarName]) {
            const newValue = dynamicEnv[envVarName];
            modifiedArg = modifiedArg.replace(fullMatch, newValue);
            console.log(`âœ… Replaced ${fullMatch} with "${newValue}"`);
          } else {
            // å¦‚æœdynamicEnvä¸­æ²¡æœ‰ï¼Œå°è¯•ä»process.envè·å–
            const processEnvValue = process.env[envVarName] || '';
            modifiedArg = modifiedArg.replace(fullMatch, processEnvValue);
            console.log(`âš ï¸ Used process.env value for ${envVarName}: "${processEnvValue}"`);
          }
        }
        
        // å¦‚æœå‚æ•°è¢«ä¿®æ”¹äº†ï¼Œæ›´æ–°å®ƒ
        if (modifiedArg !== arg) {
          dynamicArgs[i] = modifiedArg;
          console.log(`Updated arg ${i}: "${arg}" -> "${modifiedArg}"`);
        }
      }
    }
    
    console.log(`Final Dynamic Args: ${JSON.stringify(dynamicArgs, null, 2)}`);
    return dynamicArgs;
  }
  
  /**
   * å¤„ç†å·¥å…·è¿”å›ç»“æœ - æå–åŸå§‹æ•°æ®ï¼Œä¸åšæ ¼å¼åŒ–å¤„ç†
   * @param rawResult åŸå§‹è¿”å›ç»“æœ
   * 
   * æ³¨é‡Šè¯´æ˜ï¼šè¿™ä¸ªæ–¹æ³•å·²ç»ä¸å†ä½¿ç”¨ï¼Œå› ä¸ºå®ƒä¼šå¯¹ä¸åŒMCPçš„è¿”å›æ ¼å¼åšå‡è®¾ï¼Œ
   * å®¹æ˜“å‡ºç°æ•°æ®ä¸¢å¤±æˆ–æ ¼å¼é”™è¯¯ã€‚ç°åœ¨ç›´æ¥å°†åŸå§‹ç»“æœä¼ ç»™LLMå¤„ç†æ›´å¯é ã€‚
   */
  // private processToolResult(rawResult: any): any {
  //   if (!rawResult) return null;
  //   
  //   logger.info(`ğŸ” Processing MCP tool raw return result: ${JSON.stringify(rawResult, null, 2)}`);
  //   
  //   // ç®€åŒ–å¤„ç†é€»è¾‘ï¼šç›´æ¥æå–æ•°æ®ï¼Œè®©LLMæ¥å¤„ç†æ‰€æœ‰æ ¼å¼åŒ–
  //   let extractedData;
  //   
  //   try {
  //     // å°è¯•æå–å®é™…çš„æ•°æ®å†…å®¹
  //     if (rawResult.content) {
  //       if (Array.isArray(rawResult.content)) {
  //         // å¦‚æœæ˜¯æ•°ç»„ï¼Œæå–ç¬¬ä¸€ä¸ªå…ƒç´ çš„textæˆ–æ•´ä¸ªæ•°ç»„
  //         const firstContent = rawResult.content[0];
  //         if (firstContent && firstContent.text) {
  //           extractedData = firstContent.text;
  //         } else {
  //           extractedData = rawResult.content;
  //         }
  //       } else if (typeof rawResult.content === 'object') {
  //         // å¦‚æœæ˜¯å¯¹è±¡ï¼Œæå–textå­—æ®µæˆ–æ•´ä¸ªå¯¹è±¡
  //         extractedData = rawResult.content.text || rawResult.content;
  //       } else {
  //         // å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥ä½¿ç”¨
  //         extractedData = rawResult.content;
  //       }
  //     } else {
  //       // å¦‚æœæ²¡æœ‰contentå­—æ®µï¼Œä½¿ç”¨æ•´ä¸ªç»“æœ
  //       extractedData = rawResult;
  //     }
  //     
  //     // å¦‚æœæå–çš„æ•°æ®æ˜¯å¯¹è±¡ï¼Œè½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²
  //     if (typeof extractedData === 'object') {
  //       extractedData = JSON.stringify(extractedData, null, 2);
  //     } else if (typeof extractedData !== 'string') {
  //       extractedData = String(extractedData);
  //     }
  //     
  //   } catch (error) {
  //     logger.warn(`Error processing tool result, using raw result: ${error}`);
  //     extractedData = JSON.stringify(rawResult, null, 2);
  //   }
  //   
  //   logger.info(`ğŸ“¤ MCP tool extracted data: ${extractedData}`);
  //   return extractedData;
  // }
  
  /**
   * ä½¿ç”¨LLMå°†åŸå§‹ç»“æœæ ¼å¼åŒ–ä¸ºæ˜“è¯»çš„Markdownæ ¼å¼
   * @param rawResult åŸå§‹ç»“æœ
   * @param mcpName MCPåç§°
   * @param actionName åŠ¨ä½œåç§°
   * @returns æ ¼å¼åŒ–åçš„Markdownå†…å®¹
   */
  private async formatResultWithLLM(rawResult: any, mcpName: string, actionName: string, userLanguage?: SupportedLanguage): Promise<string> {
    try {
      logger.info(`ğŸ¤– Using LLM to format result for ${mcpName}/${actionName}`);
      
      // æå–å®é™…å†…å®¹
      let actualContent = rawResult;
      if (rawResult && typeof rawResult === 'object' && rawResult.content) {
        if (Array.isArray(rawResult.content) && rawResult.content.length > 0) {
          actualContent = rawResult.content[0].text || rawResult.content[0];
        } else if (rawResult.content.text) {
          actualContent = rawResult.content.text;
        } else {
          actualContent = rawResult.content;
        }
      }
      
      // ğŸŒ å¦‚æœæ²¡æœ‰ä¼ å…¥ç”¨æˆ·è¯­è¨€ï¼Œå°è¯•ä»åŸå§‹æ•°æ®ä¸­æ£€æµ‹
      if (!userLanguage && typeof actualContent === 'string') {
        userLanguage = resolveUserLanguage(actualContent);
      }
      
      // æ„å»ºæ ¼å¼åŒ–æç¤ºè¯
      const formatPrompt = `You are a professional data presentation specialist. Your task is to extract useful information from raw API/tool responses and present it in a clean, readable Markdown format.

MCP Tool: ${mcpName}
Action: ${actionName}
Raw Result:
${typeof actualContent === 'string' ? actualContent : JSON.stringify(actualContent, null, 2)}

FORMATTING RULES:
1. **Smart Data Recognition**: Analyze the raw result to identify if it contains:
   - Valid data (JSON arrays, objects, structured information)
   - Error messages or failures
   - Mixed results (some data with warnings/errors)

2. **Format Based on Content Type**:
   - **Valid Data**: Extract and present the meaningful information
   - **Error Results**: Explain what went wrong in user-friendly terms
   - **Mixed Results**: Present available data and note any issues

3. **Presentation Guidelines**:
   - Use proper Markdown formatting (headers, lists, tables, etc.)
   - Highlight important numbers, dates, and key information
   - Remove technical details, error codes, and unnecessary metadata
   - If the result contains financial data, format numbers properly (e.g., $1,234.56)
   - If the result contains lists or arrays, present them as bullet points or tables
   - Use emojis where appropriate to make the content more engaging
   - Keep the formatting clean and professional

4. **Error Handling**:
   - If the result indicates an error, explain it clearly in user-friendly language
   - For API errors, translate technical messages into understandable explanations
   - For partial failures, present what data is available and note limitations

5. **Data Extraction**:
   - For JSON arrays: Present as organized lists or tables
   - For nested objects: Extract key-value pairs meaningfully
   - For mixed formats: Adapt presentation to the data structure

OUTPUT FORMAT:
- Start with a brief summary of what was retrieved or what happened
- Present the main data in an organized manner (or explain the error)
- End with any relevant notes or observations

ğŸš¨ CRITICAL: Return ONLY the raw Markdown content without any code block wrappers. 
âŒ DO NOT wrap your response in \`\`\`markdown \`\`\` or \`\`\` \`\`\` blocks.
âœ… Return the markdown content directly, ready for immediate display.

Example of CORRECT output:
# Latest Tweets from @username
Here are the recent tweets...

Example of WRONG output:
\`\`\`markdown
# Latest Tweets from @username
Here are the recent tweets...
\`\`\`

IMPORTANT: Your response should be ready-to-display markdown content, not wrapped in any code blocks.${userLanguage ? getLanguageInstruction(userLanguage) : ''}`;

      const response = await this.llm.invoke([
        new SystemMessage(formatPrompt)
      ]);
      
      let formattedResult = response.content.toString().trim();
      
      // ğŸ”§ å…³é”®ä¿®å¤ï¼šæ¸…ç†å¯èƒ½çš„markdownä»£ç å—åŒ…è£…
      if (formattedResult.startsWith('```markdown\n') && formattedResult.endsWith('\n```')) {
        formattedResult = formattedResult.slice(12, -4).trim();
        logger.info(`ğŸ”§ Cleaned markdown code block wrapper`);
      } else if (formattedResult.startsWith('```\n') && formattedResult.endsWith('\n```')) {
        formattedResult = formattedResult.slice(4, -4).trim();
        logger.info(`ğŸ”§ Cleaned generic code block wrapper`);
      }
      
      logger.info(`âœ… Result formatted successfully`);
      
      return formattedResult;
    } catch (error) {
      logger.error(`Failed to format result with LLM:`, error);
      // é™çº§å¤„ç†ï¼šè¿”å›åŸºæœ¬æ ¼å¼åŒ–çš„ç»“æœ
      return `### ${actionName} ç»“æœ\n\n\`\`\`json\n${JSON.stringify(rawResult, null, 2)}\n\`\`\``;
    }
  }
  

  
  /**
   * ç”Ÿæˆä»»åŠ¡ç»“æœæ‘˜è¦
   * @param taskContent ä»»åŠ¡å†…å®¹
   * @param stepResults æ­¥éª¤ç»“æœ
   */
  private async generateResultSummary(taskContent: string, stepResults: any[]): Promise<string> {
    try {
      logger.info('Generating task result summary');
      
      // è®¡ç®—æˆåŠŸå’Œå¤±è´¥æ­¥éª¤æ•°
      const successSteps = stepResults.filter(step => step.success).length;
      const failedSteps = stepResults.length - successSteps;
      
      // å‡†å¤‡æ­¥éª¤ç»“æœè¯¦æƒ…
      const stepDetails = stepResults.map(step => {
        if (step.success) {
          // å¦‚æœç»“æœå·²ç»æ˜¯Markdownæ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨å‰100ä¸ªå­—ç¬¦
          const resultPreview = typeof step.result === 'string' ? 
            step.result.replace(/\n/g, ' ').substring(0, 100) : 
            JSON.stringify(step.result).substring(0, 100);
          return `æ­¥éª¤${step.step}: æˆåŠŸæ‰§è¡Œ - ${resultPreview}${resultPreview.length >= 100 ? '...' : ''}`;
        } else {
          return `æ­¥éª¤${step.step}: æ‰§è¡Œå¤±è´¥ - ${step.error}`;
        }
      }).join('\n');
      
      const response = await this.llm.invoke([
        new SystemMessage(`You are a professional task summary specialist responsible for summarizing complex workflow execution results into detailed yet easy-to-understand reports.
Please generate a comprehensive report based on the original task requirements and execution results, including the following:

1. Task execution overview - total steps, successful steps, failed steps
2. Successfully completed operations and results achieved
3. If any steps failed, detailed explanation of the failure reasons and impacts
4. Overall task outcomes and value
5. Recommendations for the user (if applicable)

Please note that this summary will be presented directly to the user and should use friendly language and formatting to ensure the user understands the complete process and results of the task execution.
Avoid technical jargon while maintaining professionalism and accuracy. Please especially emphasize the value and outcomes the task has delivered to the user.`),
        new HumanMessage(`Task content: ${taskContent}

Execution statistics:
- Total steps: ${stepResults.length}
- Successful steps: ${successSteps}
- Failed steps: ${failedSteps}

Step details:
${stepDetails}

Based on the above task execution information, please generate a complete execution report, focusing on what this task has done for the user and what specific outcomes have been achieved.`)
      ]);
      
      return response.content.toString();
    } catch (error) {
      logger.error('Generating result summary failed:', error);
      return `ä»»åŠ¡æ‰§è¡Œå®Œæˆï¼Œå…±æ‰§è¡Œäº†${stepResults.length}ä¸ªæ­¥éª¤ï¼ŒæˆåŠŸ${stepResults.filter(s => s.success).length}ä¸ªï¼Œå¤±è´¥${stepResults.filter(s => !s.success).length}ä¸ªã€‚è¯·æŸ¥çœ‹è¯¦ç»†çš„æ­¥éª¤ç»“æœäº†è§£æ›´å¤šä¿¡æ¯ã€‚`;
    }
  }

  /**
   * æ„å»ºLangChainé“¾å¼å·¥ä½œæµï¼ˆå¸¦æ¶ˆæ¯å­˜å‚¨åŠŸèƒ½ï¼‰
   * @param workflow å·¥ä½œæµé…ç½®
   * @param taskId ä»»åŠ¡ID
   * @param conversationId ä¼šè¯ID
   * @param stream æµå¼è¾“å‡ºå›è°ƒ
   * @returns LangChainçš„RunnableSequenceideal_face_score
   */
  private async buildLangChainWorkflowChainWithMessages(
    workflow: Array<{ step: number; mcp: string; action: string; input?: any }>,
    taskId: string,
    conversationId: string | undefined,
    stream: (data: any) => void
  ): Promise<RunnableSequence> {
    logger.info(`ğŸ”— Building LangChain workflow chain with message storage for ${workflow.length} steps`);
      
    // åˆ›å»ºå·¥ä½œæµæ­¥éª¤çš„Runnableæ•°ç»„
    const runnables = workflow.map((step) => {
      return RunnablePassthrough.assign({
        [`step${step.step}`]: async (previousResults: any) => {
          const stepNumber = step.step;
          const mcpName = step.mcp;
          const actionName = step.action;
          
          // å¤„ç†è¾“å…¥ï¼šä¼˜å…ˆä½¿ç”¨ä¸Šä¸€æ­¥çš„ç»“æœï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é…ç½®çš„è¾“å…¥
          let input = step.input;
          
          // å¦‚æœæ˜¯ç¬¬ä¸€æ­¥ä¹‹åçš„æ­¥éª¤ï¼Œå°è¯•ä½¿ç”¨å‰ä¸€æ­¥çš„ç»“æœ
          if (stepNumber > 1 && previousResults[`step${stepNumber - 1}`]) {
            const prevResult = previousResults[`step${stepNumber - 1}`];
            // æ™ºèƒ½æå–å‰ä¸€æ­¥ç»“æœä¸­çš„æœ‰ç”¨æ•°æ®
            input = await this.extractUsefulDataFromResult(prevResult, actionName);
      }
      
          // ç¡®ä¿è¾“å…¥æ ¼å¼æ­£ç¡®
          input = this.processStepInput(input || {});
          
          logger.info(`ğŸ“ LangChain Step ${stepNumber}: ${mcpName} - ${actionName}`);
          logger.info(`ğŸ“¥ Step input: ${JSON.stringify(input, null, 2)}`);
          
          // åˆ›å»ºæ­¥éª¤æ¶ˆæ¯ï¼ˆæµå¼ï¼‰
          let stepMessageId: string | undefined;
          if (conversationId) {
            const stepMessage = await messageDao.createStreamingMessage({
              conversationId,
              content: `Executing step ${stepNumber}: ${actionName}...`,
              type: MessageType.ASSISTANT,
              intent: MessageIntent.TASK,
              taskId,
              metadata: {
                stepType: MessageStepType.EXECUTION,
                stepNumber,
                stepName: actionName,
                totalSteps: workflow.length,
                taskPhase: 'execution',
                contentType: stepNumber === workflow.length ? 'final_result' : 'step_thinking',  // åŒºåˆ†æ€è€ƒè¿‡ç¨‹å’Œæœ€ç»ˆç»“æœ
                // ğŸ”§ æ–°å¢ï¼šè¯¦ç»†çš„å·¥å…·è°ƒç”¨ä¿¡æ¯ï¼ˆä»…åœ¨metadataä¸­ï¼Œä¸å½±å“å†…å®¹ï¼‰
                toolDetails: {
                  toolType: 'mcp',
                  toolName: actionName,
                  mcpName: mcpName,
                  args: input,
                  timestamp: new Date().toISOString()
                }
              }
            });
            stepMessageId = stepMessage.id;
        
            // å¢é‡ä¼šè¯æ¶ˆæ¯è®¡æ•°
            await conversationDao.incrementMessageCount(conversationId);
          }
        
        // å‘é€æ­¥éª¤å¼€å§‹ä¿¡æ¯
        stream({ 
          event: 'step_start', 
          data: { 
            step: stepNumber,
            mcpName,
            actionName,
            input: typeof input === 'object' ? JSON.stringify(input) : input
          } 
        });
        
        try {
          // æ ‡å‡†åŒ–MCPåç§°
          const actualMcpName = this.normalizeMCPName(mcpName);
            
            // è°ƒç”¨MCPå·¥å…·
            const stepResult = await this.callMCPTool(actualMcpName, actionName, input, taskId);
            
            // å¦‚æœæ˜¯æœ€åä¸€æ­¥ï¼Œä½¿ç”¨æµå¼æ ¼å¼åŒ–å¹¶å‘é€final_result_chunkäº‹ä»¶
            let formattedResult: string;
            if (stepNumber === workflow.length) {
              // æœ€åä¸€æ­¥ä½¿ç”¨æµå¼æ ¼å¼åŒ–
              formattedResult = await this.formatResultWithLLMStream(
                stepResult, 
                actualMcpName, 
                actionName,
                (chunk: string) => {
                  // å‘é€æµå¼final_resultå—
                  stream({
                    event: 'final_result_chunk',
                    data: { chunk }
                  });
                }
              );
            } else {
              // å…¶ä»–æ­¥éª¤ä½¿ç”¨æ™®é€šæ ¼å¼åŒ–
              formattedResult = await this.formatResultWithLLM(stepResult, actualMcpName, actionName);
            }
            
            // ğŸ”§ å­˜å‚¨åŸå§‹ç»“æœå’Œæ ¼å¼åŒ–ç»“æœæ¶ˆæ¯
            if (conversationId) {
              // 1. åˆ›å»ºåŸå§‹ç»“æœæ¶ˆæ¯
              const rawContent = `Step ${stepNumber} Raw Result: ${actionName}

${JSON.stringify(stepResult, null, 2)}`;

              await messageDao.createMessage({
                conversationId,
                content: rawContent,
                type: MessageType.ASSISTANT,
                intent: MessageIntent.TASK,
                taskId,
                metadata: {
                  stepType: MessageStepType.EXECUTION,
                  stepNumber,
                  stepName: actionName,
                  totalSteps: workflow.length,
                  taskPhase: 'execution',
                  contentType: 'raw_result',
                  isComplete: true,
                  toolDetails: {
                    toolType: 'mcp',
                    toolName: actionName,
                    mcpName: mcpName,
                    args: input,
                    timestamp: new Date().toISOString()
                  },
                  executionDetails: {
                    rawResult: stepResult,
                    success: true,
                    processingInfo: {
                      originalDataSize: JSON.stringify(stepResult).length,
                      processingTime: new Date().toISOString()
                    }
                  }
                }
              });

              await conversationDao.incrementMessageCount(conversationId);

              // 2. åˆ›å»ºæ ¼å¼åŒ–ç»“æœæ¶ˆæ¯
              const formattedContent = `Step ${stepNumber} Formatted Result: ${actionName}

${formattedResult}`;

              await messageDao.createMessage({
                conversationId,
                content: formattedContent,
                type: MessageType.ASSISTANT,
                intent: MessageIntent.TASK,
                taskId,
                metadata: {
                  stepType: MessageStepType.EXECUTION,
                  stepNumber,
                  stepName: actionName,
                  totalSteps: workflow.length,
                  taskPhase: 'execution',
                  contentType: 'formatted_result',
                  isComplete: true,
                  toolDetails: {
                    toolType: 'mcp',
                    toolName: actionName,
                    mcpName: mcpName,
                    args: input,
                    timestamp: new Date().toISOString()
                  },
                  executionDetails: {
                    formattedResult: formattedResult,
                    success: true,
                    processingInfo: {
                      formattedDataSize: formattedResult.length,
                      processingTime: new Date().toISOString()
                    }
                  }
                }
              });

              await conversationDao.incrementMessageCount(conversationId);
            }

            // å®ŒæˆåŸæœ‰çš„æµå¼æ­¥éª¤æ¶ˆæ¯
            if (stepMessageId) {
              await messageDao.completeStreamingMessage(stepMessageId, formattedResult);
            }
            
            // ä¿å­˜æ­¥éª¤ç»“æœï¼ˆä¿å­˜æ ¼å¼åŒ–åçš„ç»“æœï¼‰
            await taskExecutorDao.saveStepResult(taskId, stepNumber, true, formattedResult);
          
            // å‘é€æ­¥éª¤å®Œæˆä¿¡æ¯ï¼ˆå‘é€æ ¼å¼åŒ–åçš„ç»“æœï¼‰
          stream({ 
            event: 'step_complete', 
            data: { 
              step: stepNumber,
              success: true,
                result: formattedResult,
                rawResult: stepResult // ä¿ç•™åŸå§‹MCPç»“æœä¾›è°ƒè¯•
            } 
          });
          
            return {
              step: stepNumber,
              success: true,
              result: formattedResult,
              rawResult: stepResult,
              parsedData: this.parseResultData(stepResult) // è§£æç»“æ„åŒ–æ•°æ®ä¾›ä¸‹ä¸€æ­¥ä½¿ç”¨
            };
        } catch (error) {
            logger.error(`âŒ LangChain Step ${stepNumber} failed:`, error);
          const errorMsg = error instanceof Error ? error.message : String(error);
          
          // ğŸ”§ Enhanced: Use error handler to analyze errors with LLM for task execution
          let detailedError = null;
          let isMCPConnectionError = false;
          let mcpName: string | undefined;
          
          try {
            // Extract MCP name from step context or error message
            if (step.mcp) {
              mcpName = step.mcp;
            } else if (errorMsg.includes('MCP ')) {
              const mcpMatch = errorMsg.match(/MCP\s+([^\s]+)/);
              if (mcpMatch) {
                mcpName = mcpMatch[1];
              }
            }
            
            const { MCPErrorHandler } = await import('./mcpErrorHandler.js');
            const errorToAnalyze = error instanceof Error ? error : new Error(String(error));
            const errorDetails = await MCPErrorHandler.analyzeError(errorToAnalyze, mcpName);
            detailedError = MCPErrorHandler.formatErrorForFrontend(errorDetails);
            
            // Check if this is an MCP connection/authentication error
            isMCPConnectionError = this.isMCPConnectionError(errorDetails.type);
            
            if (isMCPConnectionError && mcpName) {
              // Send specialized MCP connection error event
              stream({
                event: 'mcp_connection_error',
                data: {
                  mcpName: mcpName,
                  step: stepNumber,
                  errorType: errorDetails.type,
                  title: errorDetails.title,
                  message: errorDetails.userMessage,
                  suggestions: errorDetails.suggestions,
                  authFieldsRequired: errorDetails.authFieldsRequired,
                  isRetryable: errorDetails.isRetryable,
                  requiresUserAction: errorDetails.requiresUserAction,
                  llmAnalysis: errorDetails.llmAnalysis,
                  originalError: errorDetails.originalError,
                  timestamp: new Date().toISOString()
                }
              });
            }
          } catch (analysisError) {
            logger.warn('Error analysis failed:', analysisError);
          }
          
            // å®Œæˆæ­¥éª¤æ¶ˆæ¯ï¼ˆé”™è¯¯çŠ¶æ€ï¼‰
            if (stepMessageId) {
              await messageDao.completeStreamingMessage(stepMessageId, `æ‰§è¡Œå¤±è´¥: ${errorMsg}`);
            }
            
            // ä¿å­˜é”™è¯¯ç»“æœ
          await taskExecutorDao.saveStepResult(taskId, stepNumber, false, errorMsg);
          
          // Send regular step error event if not MCP connection error
          if (!isMCPConnectionError) {
          stream({ 
            event: 'step_error', 
            data: { 
              step: stepNumber,
                error: errorMsg,
                detailedError: detailedError
            } 
          });
          }
            
            return {
              step: stepNumber,
              success: false,
              error: errorMsg
            };
          }
        }
        });
      });
      
    // ä½¿ç”¨pipeæ–¹æ³•åˆ›å»ºé“¾å¼è°ƒç”¨
    if (runnables.length === 0) {
      throw new Error('Workflow must have at least one step');
    }
    
    // ä½¿ç”¨reduceåˆ›å»ºé“¾å¼è°ƒç”¨
    const chain = runnables.reduce((prev, current, index) => {
      if (index === 0) {
        return current;
      }
      return prev.pipe(current);
    }, runnables[0] as any);
    
    return chain as RunnableSequence;
  }
  
  /**
   * æµå¼ç”Ÿæˆç»“æœæ‘˜è¦ï¼ˆå¸¦æ¶ˆæ¯æ›´æ–°åŠŸèƒ½ï¼‰
   * @param taskContent ä»»åŠ¡å†…å®¹
   * @param stepResults æ­¥éª¤ç»“æœ
   * @param streamCallback æµå¼å›è°ƒå‡½æ•°
   * @param summaryMessageId æ‘˜è¦æ¶ˆæ¯IDï¼ˆç”¨äºæ›´æ–°æ¶ˆæ¯å†…å®¹ï¼‰
   */
  private async generateResultSummaryStreamWithMessage(
    taskContent: string, 
    stepResults: any[], 
    streamCallback: (chunk: string) => void,
    summaryMessageId?: string
  ): Promise<void> {
    try {
      logger.info('Streaming generation of task result summary with message update');
      
      // è®¡ç®—æˆåŠŸå’Œå¤±è´¥æ­¥éª¤æ•°
      const successSteps = stepResults.filter(step => step.success).length;
      const failedSteps = stepResults.length - successSteps;
      
      // å‡†å¤‡æ­¥éª¤ç»“æœè¯¦æƒ…
      const stepDetails = stepResults.map(step => {
        if (step.success) {
          // å¦‚æœç»“æœå·²ç»æ˜¯Markdownæ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨å‰100ä¸ªå­—ç¬¦
          const resultPreview = typeof step.result === 'string' ? 
            step.result.replace(/\n/g, ' ').substring(0, 100) : 
            JSON.stringify(step.result).substring(0, 100);
          return `æ­¥éª¤${step.step}: æˆåŠŸæ‰§è¡Œ - ${resultPreview}${resultPreview.length >= 100 ? '...' : ''}`;
        } else {
          return `æ­¥éª¤${step.step}: æ‰§è¡Œå¤±è´¥ - ${step.error}`;
        }
      }).join('\n');
      
      // åˆ›å»ºæµå¼LLMå®ä¾‹
      const streamingLlm = new ChatOpenAI({
        modelName: process.env.TASK_ANALYSIS_MODEL || 'gpt-4o',
        temperature: 0.7,
        openAIApiKey: process.env.OPENAI_API_KEY,
        streaming: true
      });
      
      // åˆ›å»ºæ¶ˆæ¯
      const messages = [
        new SystemMessage(`You are a professional task summary specialist responsible for summarizing complex workflow execution results into detailed yet easy-to-understand reports.
Please generate a comprehensive report based on the original task requirements and execution results, including the following:

1. Task execution overview - total steps, successful steps, failed steps
2. Successfully completed operations and results achieved
3. If any steps failed, detailed explanation of the failure reasons and impacts
4. Overall task outcomes and value
5. Recommendations for the user (if applicable)

Please note that this summary will be presented directly to the user and should use friendly language and formatting to ensure the user understands the complete process and results of the task execution.
Avoid technical jargon while maintaining professionalism and accuracy. Please especially emphasize the value and outcomes the task has delivered to the user.`),
        new HumanMessage(`Task content: ${taskContent}

Execution statistics:
- Total steps: ${stepResults.length}
- Successful steps: ${successSteps}
- Failed steps: ${failedSteps}

Step details:
${stepDetails}

Based on the above task execution information, please generate a complete execution report, focusing on what this task has done for the user and what specific outcomes have been achieved.`)
      ];
      
      // è·å–æµ
      const stream = await streamingLlm.stream(messages);
      
      // ç´¯ç§¯å®Œæ•´çš„æ‘˜è¦å†…å®¹
      let fullSummary = '';
      
      // å¤„ç†æµçš„å†…å®¹
      for await (const chunk of stream) {
        if (chunk.content) {
          // ä¿®å¤ç±»å‹é”™è¯¯ï¼Œç¡®ä¿å†…å®¹ä¸ºå­—ç¬¦ä¸²
          const chunkText = typeof chunk.content === 'string' 
            ? chunk.content 
            : JSON.stringify(chunk.content);
          
          fullSummary += chunkText;
          streamCallback(chunkText);
        }
      }
      
      // å®Œæˆæ‘˜è¦æ¶ˆæ¯
      if (summaryMessageId) {
        await messageDao.completeStreamingMessage(summaryMessageId, `## ğŸ“Š ä»»åŠ¡æ‰§è¡Œæ‘˜è¦

${fullSummary}`);
      }
    } catch (error) {
      logger.error('Streaming generation of result summary failed:', error);
      const fallbackSummary = `Task execution completed, executed ${stepResults.length} steps in total, ${stepResults.filter(s => s.success).length} successful, ${stepResults.filter(s => !s.success).length} failed. Please check detailed step results for more information.`;
      
      streamCallback(fallbackSummary);
      
      // å®Œæˆæ‘˜è¦æ¶ˆæ¯ï¼ˆé™çº§å¤„ç†ï¼‰
      if (summaryMessageId) {
        await messageDao.completeStreamingMessage(summaryMessageId, `## ğŸ“Š ä»»åŠ¡æ‰§è¡Œæ‘˜è¦

${fallbackSummary}`);
      }
    }
  }

  /**
   * ä»å‰ä¸€æ­¥ç»“æœä¸­æå–æœ‰ç”¨æ•°æ®ï¼ˆä½¿ç”¨LLMæ™ºèƒ½è½¬æ¢ï¼‰
   * @param prevResult å‰ä¸€æ­¥çš„ç»“æœ
   * @param nextAction ä¸‹ä¸€æ­¥çš„åŠ¨ä½œ
   * @returns æå–çš„æ•°æ®
   */
  private async extractUsefulDataFromResult(prevResult: any, nextAction: string): Promise<any> {
    try {
      logger.info(`ğŸ” Using LLM to extract useful data for next action: ${nextAction}`);
      
      // å‡†å¤‡å‰ä¸€æ­¥ç»“æœçš„æ–‡æœ¬è¡¨ç¤º
      let rawResult = prevResult.result;
      if (typeof rawResult === 'object' && rawResult.content) {
        if (Array.isArray(rawResult.content) && rawResult.content[0]?.text) {
          rawResult = rawResult.content[0].text;
        } else if (rawResult.content.text) {
          rawResult = rawResult.content.text;
        }
      }
      
      const conversionPrompt = `You are an intelligent data transformation assistant. Your task is to intelligently transform the output from one tool into the appropriate input for the next tool in a workflow chain.

CRITICAL: DO NOT use any hardcoded examples or templates. Analyze the actual data and requirements to create appropriate parameters.

CONTEXT:
Previous step output: ${typeof rawResult === 'string' ? rawResult : JSON.stringify(rawResult, null, 2)}
Next action/tool: ${nextAction}

TRANSFORMATION PRINCIPLES:
1. **Analyze the tool name/action**: Understand what the next tool expects based on its name
2. **Extract relevant data**: From previous output, extract only the data relevant to the next tool
3. **Format according to tool type**:
   - For social media tools (tweet, post): Extract key insights and create engaging content
   - For API tools: Structure data according to common API patterns
   - For content creation: Transform data into readable text
   - For database operations: Create properly structured data objects

4. **Common tool patterns**:
   - create_tweet/post_tweet: Expects {"text": "content up to 280 chars"}
     CRITICAL: Twitter has a 280 character limit! If content is longer:
     * For single tweet: Summarize to fit within 280 chars
     * For thread request: Create first tweet only, mentioning it's part 1 of a thread
   - create_post/publish: Expects {"content": "formatted content"}
   - search operations: Expects {"query": "search terms"}
   - data fetching: Expects specific IDs or parameters

5. **Smart content generation**:
   - For Twitter: MUST be under 280 characters! Use concise language, abbreviations if needed, but preserve important URLs
   - For cryptocurrency/financial data: Highlight price, changes, trends
   - For analysis results: Summarize key findings concisely and include reference links
   - For lists/collections: Format as readable bullet points or threads, include source URLs
   - ALWAYS extract and include original URLs/links when available in the source data

OUTPUT FORMAT:
Return a JSON object with exactly this structure:
{
  "transformedData": { /* the actual parameters for the next tool */ },
  "reasoning": "brief explanation of the transformation logic"
}

IMPORTANT: Base your transformation purely on the tool name and previous data. Do not use any pre-defined templates.

Transform the data now:`;

      const response = await this.llm.invoke([
        new SystemMessage(conversionPrompt)
      ]);

      let transformedData;
      try {
        const responseText = response.content.toString().trim();
        // æ¸…ç†å¯èƒ½çš„markdownæ ¼å¼
        const cleanedText = responseText
          .replace(/```json\s*/g, '')
          .replace(/```\s*$/g, '')
          .trim();
        
        const parsed = JSON.parse(cleanedText);
        transformedData = parsed.transformedData || parsed;
        
        logger.info(`ğŸ¤– LLMæ•°æ®è½¬æ¢æˆåŠŸ: ${JSON.stringify(transformedData, null, 2)}`);
      } catch (parseError) {
        logger.error(`è§£æLLMè½¬æ¢ç»“æœå¤±è´¥: ${response.content}`);
        // å›é€€å¤„ç†
        transformedData = rawResult;
      }

      return transformedData;
    } catch (error) {
      logger.error(`âŒ Failed to transform data using LLM: ${error}`);
      
      // é™çº§å¤„ç†ï¼šå°è¯•ç®€å•æå–
      if (prevResult.result) {
        const resultStr = JSON.stringify(prevResult.result);
        // å¦‚æœæ˜¯æ¨æ–‡ç›¸å…³ï¼Œå°è¯•ç”Ÿæˆç®€å•å†…å®¹
        if (nextAction.toLowerCase().includes('tweet') || nextAction.toLowerCase().includes('post')) {
          return {
            text: 'ğŸš€ Check out the latest crypto market updates! #Crypto #DeFi'
          };
        }
        // å¦åˆ™è¿”å›è§£æçš„æ•°æ®æˆ–åŸå§‹ç»“æœ
        return prevResult.parsedData || prevResult.result;
      }
      
      return {};
    }
  }

  /**
   * è§£æç»“æœæ•°æ®ä¸ºç»“æ„åŒ–æ ¼å¼
   * @param result åŸå§‹ç»“æœ
   * @returns è§£æåçš„ç»“æ„åŒ–æ•°æ®
   */
  private parseResultData(result: any): any {
    try {
      if (typeof result === 'string') {
        // å°è¯•è§£æJSON
        const parsed = JSON.parse(result);
        
        // æå–å…³é”®æ•°æ®
        if (parsed.data) {
          return parsed.data;
        } else if (parsed.summary) {
          return parsed.summary;
        } else {
          return parsed;
        }
      }
      return result;
    } catch (error) {
      // å¦‚æœä¸æ˜¯JSONï¼Œè¿”å›åŸå§‹æ•°æ®
      return { rawData: result };
    }
  }

  /**
   * ç”Ÿæˆç¤¾äº¤åª’ä½“å‘å¸ƒå†…å®¹
   * @param data æ•°æ®
   * @returns å‘å¸ƒå†…å®¹
   */
  private generatePostContent(data: any): string {
    if (data.symbol && data.price) {
      return `${data.symbol} current price: $${data.price}${data.percent_change_24h ? ` (${data.percent_change_24h > 0 ? '+' : ''}${data.percent_change_24h}%)` : ''}`;
    }
    return JSON.stringify(data, null, 2);
  }

  /**
   * æµå¼æ‰§è¡Œä»»åŠ¡å·¥ä½œæµ
   * @param taskId ä»»åŠ¡ID
   * @param stream å“åº”æµï¼Œç”¨äºå®æ—¶å‘é€æ‰§è¡Œç»“æœ
   * @returns æ˜¯å¦æ‰§è¡ŒæˆåŠŸ
   */
  async executeTaskStream(taskId: string, stream: (data: any) => void): Promise<boolean> {
    try {
      logger.info(`ğŸš€ Starting streaming task execution with LangChain [Task ID: ${taskId}]`);
      
      // å‘é€æ‰§è¡Œå¼€å§‹ä¿¡æ¯
      stream({ 
        event: 'execution_start', 
        data: { taskId, timestamp: new Date().toISOString() } 
      });
      
      // è·å–ä»»åŠ¡è¯¦æƒ…
      const task = await taskService.getTaskById(taskId);
      if (!task) {
        logger.error(`âŒ Task not found [ID: ${taskId}]`);
        stream({ event: 'error', data: { message: 'Task not found' } });
        return false;
      }
      
      // æ›´æ–°ä»»åŠ¡çŠ¶æ€
      await taskExecutorDao.updateTaskStatus(taskId, 'in_progress');
      stream({ event: 'status_update', data: { status: 'in_progress' } });
      
      // è·å–ä¼šè¯IDç”¨äºå­˜å‚¨æ¶ˆæ¯
      const conversationId = task.conversationId;
      if (!conversationId) {
        logger.warn(`Task ${taskId} has no associated conversation, execution messages will not be stored`);
      }
      
      // è·å–ä»»åŠ¡çš„å·¥ä½œæµ
      const mcpWorkflow = typeof task.mcpWorkflow === 'string' 
        ? JSON.parse(task.mcpWorkflow) 
        : task.mcpWorkflow;
      
      logger.info(`ğŸ“‹ Workflow structure: ${JSON.stringify(mcpWorkflow, null, 2)}`);
      
      // ğŸ›ï¸ æ ¹æ®å…¨å±€å¼€å…³å†³å®šæ‰§è¡Œæ–¹å¼
      if (ENABLE_INTELLIGENT_WORKFLOW) {
        // ä½¿ç”¨æ™ºèƒ½å·¥ä½œæµå¼•æ“ï¼Œå°†LLMå’Œé¢„é€‰çš„MCPå·¥å…·æ™ºèƒ½ç»“åˆæ‰§è¡Œ
        if (mcpWorkflow && mcpWorkflow.workflow && mcpWorkflow.workflow.length > 0) {
          logger.info(`ğŸ§  ä½¿ç”¨æ™ºèƒ½å·¥ä½œæµå¼•æ“æ‰§è¡Œä»»åŠ¡ï¼Œç»“åˆé¢„é€‰çš„MCPå·¥å…· [ä»»åŠ¡: ${taskId}]`);
          return await this.executeWithIntelligentWorkflow(taskId, task, stream, conversationId);
        } else {
          logger.info(`ğŸ§  ä½¿ç”¨æ™ºèƒ½å·¥ä½œæµå¼•æ“æ‰§è¡Œä»»åŠ¡ï¼Œæ— é¢„é€‰MCPå·¥å…· [ä»»åŠ¡: ${taskId}]`);
          return await this.executeWithIntelligentWorkflow(taskId, task, stream, conversationId);
        }
      }
      
      // ä¼ ç»Ÿå·¥ä½œæµæ‰§è¡Œæ–¹å¼ï¼ˆéœ€è¦é¢„å®šä¹‰å·¥ä½œæµï¼‰
      if (!mcpWorkflow || !mcpWorkflow.workflow || mcpWorkflow.workflow.length === 0) {
        logger.error(`âŒ Task execution failed: No valid workflow [Task ID: ${taskId}]`);
        
        stream({ 
          event: 'error', 
          data: { 
            message: 'Task execution failed: No valid workflow',
            details: 'Please call task analysis API /api/task/:id/analyze first'
          } 
        });
        
        await taskExecutorDao.updateTaskResult(taskId, 'failed', {
          error: 'Task execution failed: No valid workflow, please call task analysis API first'
        });
        
        return false;
      }
      
      logger.info(`ğŸ“Š ä½¿ç”¨ä¼ ç»Ÿå·¥ä½œæµæ‰§è¡Œä»»åŠ¡ [ä»»åŠ¡: ${taskId}]`);
      
      // æ£€æŸ¥ mcpManager æ˜¯å¦å·²åˆå§‹åŒ–
      if (!this.mcpManager) {
        logger.error(`âŒ mcpManager not initialized, cannot execute task [Task ID: ${taskId}]`);
        stream({ 
          event: 'error', 
          data: { 
            message: 'Task execution failed: MCP manager not initialized',
            details: 'Server configuration error, please contact administrator'
          } 
        });
        
        await taskExecutorDao.updateTaskResult(taskId, 'failed', {
          error: 'Task execution failed: MCP manager not initialized'
        });
        
        return false;
      }
      
      // åˆ›å»ºæ‰§è¡Œå¼€å§‹çš„æ¶ˆæ¯
      if (conversationId) {
        const executionStartMessage = await messageDao.createMessage({
          conversationId,
          content: `Executing task "${task.title}" with ${mcpWorkflow.workflow.length} steps...`,
          type: MessageType.ASSISTANT,
          intent: MessageIntent.TASK,
          taskId,
          metadata: {
            stepType: MessageStepType.EXECUTION,
            stepName: 'Execution Start',
            taskPhase: 'execution',
            totalSteps: mcpWorkflow.workflow.length,
            isComplete: true
          }
        });
        
        // å¢é‡ä¼šè¯æ¶ˆæ¯è®¡æ•°
        await conversationDao.incrementMessageCount(conversationId);
      }
      
      try {
        // ä½¿ç”¨LangChainæ„å»ºé“¾å¼å·¥ä½œæµï¼Œä½†æ·»åŠ æ¶ˆæ¯å­˜å‚¨åŠŸèƒ½
        logger.info(`ğŸ”— Building LangChain workflow chain for ${mcpWorkflow.workflow.length} steps`);
        const workflowChain = await this.buildLangChainWorkflowChainWithMessages(
          mcpWorkflow.workflow,
          taskId,
          conversationId,
          stream
        );
        
        // æ‰§è¡Œé“¾å¼è°ƒç”¨ï¼Œåˆå§‹è¾“å…¥åŒ…å«ä»»åŠ¡å†…å®¹
        logger.info(`â–¶ï¸ Executing LangChain workflow chain`);
        const chainResult = await workflowChain.invoke({
          taskContent: task.content,
          taskId: taskId
        });
        
        // æ”¶é›†æ‰€æœ‰æ­¥éª¤çš„ç»“æœ
        const workflowResults: any[] = [];
        let finalResult = null;
        
        // ä»chainResultä¸­æå–æ­¥éª¤ç»“æœ
        for (let i = 1; i <= mcpWorkflow.workflow.length; i++) {
          const stepResult = chainResult[`step${i}`];
          if (stepResult) {
            workflowResults.push(stepResult);
          
          // æœ€åä¸€æ­¥çš„ç»“æœä½œä¸ºæœ€ç»ˆç»“æœ
            if (i === mcpWorkflow.workflow.length && stepResult.success) {
              finalResult = stepResult.result;
            }
          }
        }
        
        // ç”Ÿæˆç»“æœæ‘˜è¦ï¼Œä½¿ç”¨æµå¼ç”Ÿæˆ
        stream({ event: 'generating_summary', data: { message: 'Generating result summary...' } });
        
        // åˆ›å»ºæ‘˜è¦æ¶ˆæ¯ï¼ˆæµå¼æ›´æ–°ï¼‰
        let summaryMessageId: string | undefined;
        if (conversationId) {
          const summaryMessage = await messageDao.createStreamingMessage({
            conversationId,
            content: 'Generating execution summary...',
            type: MessageType.ASSISTANT,
            intent: MessageIntent.TASK,
            taskId,
            metadata: {
              stepType: MessageStepType.SUMMARY,
              stepName: 'Execution Summary',
              taskPhase: 'execution',
              isComplete: false
            }
          });
          summaryMessageId = summaryMessage.id;
          
          // å¢é‡ä¼šè¯æ¶ˆæ¯è®¡æ•°
          await conversationDao.incrementMessageCount(conversationId);
        }
        
        await this.generateResultSummaryStreamWithMessage(
          task.content, 
          workflowResults, 
          (summaryChunk) => {
        stream({ 
          event: 'summary_chunk', 
          data: { content: summaryChunk } 
        });
          },
          summaryMessageId
        );
        
        // åˆ¤æ–­æ•´ä½“æ‰§è¡Œæ˜¯å¦æˆåŠŸ
        const overallSuccess = workflowResults.every(result => result.success);
      
        // ğŸ”§ æ–°å¢ï¼šå‘é€æœ€ç»ˆç»“æœç»™å‰ç«¯
        if (finalResult) {
          stream({ 
            event: 'final_result', 
            data: { 
              finalResult,
              message: 'Final execution result available'
            } 
          });
        }
      
        // ğŸ”§ ä¼˜åŒ–ï¼šåªåœ¨workflow_completeäº‹ä»¶ä¸­è¿”å›finalResultï¼Œé¿å…é‡å¤
      // å·¥ä½œæµå®Œæˆ
      stream({ 
        event: 'workflow_complete', 
        data: { 
            success: overallSuccess,
            message: overallSuccess ? 'Task execution completed successfully' : 'Task execution completed with errors',
            finalResult: finalResult // ğŸ”§ åœ¨è¿™é‡Œç»Ÿä¸€è¿”å›finalResult
          }
        });
        
        // æ›´æ–°ä»»åŠ¡çŠ¶æ€
        await taskExecutorDao.updateTaskResult(
          taskId, 
          overallSuccess ? 'completed' : 'failed',
          {
            summary: overallSuccess ? 'Task execution completed successfully' : 'Task execution completed with some failures',
        steps: workflowResults,
        finalResult
          }
        );
      
      // å‘é€ä»»åŠ¡å®Œæˆä¿¡æ¯
        stream({ 
          event: 'task_complete', 
          data: { 
            taskId, 
            success: overallSuccess
          } 
        });
        
        logger.info(`âœ… Task execution completed [Task ID: ${taskId}, Success: ${overallSuccess}]`);
        return overallSuccess;
        
      } catch (chainError) {
        logger.error(`âŒ LangChain workflow execution failed:`, chainError);
        
        // å‘é€é“¾å¼è°ƒç”¨é”™è¯¯ä¿¡æ¯
        stream({ 
          event: 'error', 
          data: { 
            message: 'Workflow chain execution failed',
            details: chainError instanceof Error ? chainError.message : String(chainError)
          }
        });
        
        await taskExecutorDao.updateTaskResult(taskId, 'failed', {
          error: `Chain execution failed: ${chainError instanceof Error ? chainError.message : String(chainError)}`
        });
        
        return false;
      }
      
    } catch (error) {
      logger.error(`Error occurred during task execution [Task ID: ${taskId}]:`, error);
      
      await taskExecutorDao.updateTaskResult(taskId, 'failed', {
        error: error instanceof Error ? error.message : String(error)
      });
      
      // å‘é€é”™è¯¯ä¿¡æ¯
      stream({ 
        event: 'error', 
        data: { 
          message: 'Task execution failed', 
          details: error instanceof Error ? error.message : String(error)
        } 
      });
      
      return false;
    }
  }

  /**
   * ä½¿ç”¨æ™ºèƒ½å·¥ä½œæµå¼•æ“æ‰§è¡Œä»»åŠ¡
   * @param taskId ä»»åŠ¡ID
   * @param task ä»»åŠ¡å¯¹è±¡
   * @param stream æµå¼å›è°ƒ
   * @param conversationId ä¼šè¯ID
   * @returns æ‰§è¡Œæ˜¯å¦æˆåŠŸ
   */
  private async executeWithIntelligentWorkflow(
    taskId: string, 
    task: any, 
    stream: (data: any) => void,
    conversationId?: string
  ): Promise<boolean> {
    try {
      logger.info(`ğŸ§  ä½¿ç”¨æ™ºèƒ½å·¥ä½œæµå¼•æ“æ‰§è¡Œä»»åŠ¡ [ä»»åŠ¡: ${taskId}]`);
      
      // ğŸ”§ ä½¿ç”¨å¢å¼ºçš„æ™ºèƒ½Taskå¼•æ“ï¼ˆç»“åˆAgentå¼•æ“ä¼˜åŠ¿ï¼‰
      const { enhancedIntelligentTaskService } = await import('./enhancedIntelligentTaskEngine.js');
      
      // skipAnalysis=false è¡¨ç¤ºå¦‚æœä»»åŠ¡è¿˜æœªåˆ†æï¼Œä¼šå…ˆè¿›è¡Œåˆ†æ
      return await enhancedIntelligentTaskService.executeTaskEnhanced(taskId, stream, false);
      
    } catch (error) {
      logger.error(`âŒ æ™ºèƒ½å·¥ä½œæµæ‰§è¡Œå¤±è´¥:`, error);
      
      stream({
        event: 'error',
        data: {
          message: 'æ™ºèƒ½å·¥ä½œæµæ‰§è¡Œå¤±è´¥',
          details: error instanceof Error ? error.message : String(error)
        }
      });

      // æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤±è´¥
      await taskExecutorDao.updateTaskResult(taskId, 'failed', {
        error: `æ™ºèƒ½å·¥ä½œæµæ‰§è¡Œå¤±è´¥: ${error instanceof Error ? error.message : String(error)}`
      });

      return false;
    }
  }

  /**
   * æ˜ å°„MCPåç§°ï¼Œç¡®ä¿åç§°ä¸€è‡´æ€§
   * @param mcpName åŸå§‹MCPåç§°
   * @returns æ ‡å‡†åŒ–çš„MCPåç§°
   */
  private normalizeMCPName(mcpName: string): string {
    // MCPåç§°æ˜ å°„è¡¨
    const mcpNameMapping: Record<string, string> = {
      'coinmarketcap-mcp-service': 'coinmarketcap-mcp-service',
      'coinmarketcap': 'coinmarketcap-mcp-service',
      'cmc': 'coinmarketcap-mcp-service',
      'playwright': 'playwright',
      'github-mcp-server': 'github-mcp-server',
      'github': 'github-mcp-server',
      'evm-mcp': 'evm-mcp',
      'ethereum': 'evm-mcp',
      'dexscreener-mcp-server': 'dexscreener-mcp-server',
      'dexscreener': 'dexscreener-mcp-server',
      'x-mcp': 'x-mcp',
      'twitter': 'x-mcp',
      'coingecko-mcp': 'coingecko-mcp',
      'coingecko': 'coingecko-mcp',
      'notion-mcp-server': 'notion-mcp-server',
      'notion': 'notion-mcp-server',
      '12306-mcp': '12306-mcp',
      'train': '12306-mcp',
      'AWE Core MCP Server': 'AWE Core MCP Server',
      'awe': 'AWE Core MCP Server'
    };
    
    return mcpNameMapping[mcpName] || mcpName;
  }

  /**
   * ä»æ–‡æœ¬ä¸­æå–draft_idçš„è¾…åŠ©æ–¹æ³•
   */
  private extractDraftIdFromText(text: string): string | null {
    const patterns = [
      /draft[_-]?id["\s:]*([^"\s,}]+)/i,                    // draft_id: "xxx" 
      /with\s+id\s+([a-zA-Z0-9_.-]+\.json)/i,               // "with ID thread_draft_xxx.json"
      /created\s+with\s+id\s+([a-zA-Z0-9_.-]+\.json)/i,     // "created with ID xxx.json"
      /id[:\s]+([a-zA-Z0-9_.-]+\.json)/i,                   // "ID: xxx.json" æˆ– "ID xxx.json"
      /([a-zA-Z0-9_.-]*draft[a-zA-Z0-9_.-]*\.json)/i        // ä»»ä½•åŒ…å«draftçš„.jsonæ–‡ä»¶
    ];
    
    for (const pattern of patterns) {
      const match = text.match(pattern);
      if (match) {
        return match[1];
      }
    }
    
    return null;
  }

  /**
   * x-mcpè‡ªåŠ¨å‘å¸ƒå¤„ç†ï¼šå½“create_draft_tweetæˆ–create_draft_threadæˆåŠŸåè‡ªåŠ¨å‘å¸ƒ
   */
  private async handleXMcpAutoPublish(
    mcpName: string, 
    toolName: string, 
    result: any, 
    userId?: string
  ): Promise<any> {
    // ğŸ”§ æ·»åŠ è¯¦ç»†è°ƒè¯•ä¿¡æ¯
    const normalizedMcpName = this.normalizeMCPName(mcpName);
    logger.info(`ğŸ” TaskExecutor X-MCP Auto-publish Check: mcpName="${mcpName}", normalizedMcpName="${normalizedMcpName}", toolName="${toolName}"`);
    
    // åªå¤„ç†x-mcpçš„è‰ç¨¿åˆ›å»ºæ“ä½œ
    if (normalizedMcpName !== 'x-mcp') {
      logger.info(`âŒ TaskExecutor X-MCP Auto-publish: Normalized MCP name "${normalizedMcpName}" is not "x-mcp", skipping auto-publish`);
      return result;
    }

    // æ£€æŸ¥æ˜¯å¦æ˜¯è‰ç¨¿åˆ›å»ºæ“ä½œ
    if (!toolName.includes('create_draft')) {
      logger.info(`âŒ TaskExecutor X-MCP Auto-publish: Tool name "${toolName}" does not include "create_draft", skipping auto-publish`);
      return result;
    }

    try {
      logger.info(`ğŸ”„ X-MCP Auto-publish: Detected ${toolName} completion, attempting auto-publish...`);

      // æå–draft_id
      let draftId = null;
      if (result && typeof result === 'object') {
        // å°è¯•ä»ä¸åŒçš„ç»“æœæ ¼å¼ä¸­æå–draft_id
        if (result.draft_id) {
          draftId = result.draft_id;
        } else if (result.content && Array.isArray(result.content)) {
          // MCPæ ‡å‡†æ ¼å¼
          for (const content of result.content) {
            if (content.text) {
                          try {
              const parsed = JSON.parse(content.text);
              if (parsed.draft_id) {
                draftId = parsed.draft_id;
                break;
              } else if (Array.isArray(parsed)) {
                // ğŸ”§ å¤„ç†è§£ææˆåŠŸä½†æ˜¯æ•°ç»„ç»“æ„çš„æƒ…å†µ
                for (const nestedItem of parsed) {
                  if (nestedItem && nestedItem.text) {
                    const innerText = nestedItem.text;
                    const innerMatch = this.extractDraftIdFromText(innerText);
                    if (innerMatch) {
                      draftId = innerMatch;
                      logger.info(`ğŸ“ X-MCP Auto-publish: Extracted draft_id "${draftId}" from nested JSON structure`);
                      break;
                    }
                  }
                }
                if (draftId) break;
              }
            } catch {
                // ğŸ”§ ä¿®å¤ï¼šå¤„ç†åµŒå¥—JSONç»“æ„å’Œæ–‡æœ¬æå–
                let text = content.text;
                
                // ğŸ”§ å¤„ç†åŒé‡åµŒå¥—çš„JSONæƒ…å†µï¼štextå­—æ®µæœ¬èº«æ˜¯JSONå­—ç¬¦ä¸²
                try {
                  // å°è¯•è§£ætextä½œä¸ºJSONæ•°ç»„
                  const nestedArray = JSON.parse(text);
                  if (Array.isArray(nestedArray)) {
                    // éå†åµŒå¥—æ•°ç»„ï¼Œå¯»æ‰¾åŒ…å«draftä¿¡æ¯çš„æ–‡æœ¬
                    for (const nestedItem of nestedArray) {
                      if (nestedItem && nestedItem.text) {
                        const innerText = nestedItem.text;
                        // å…ˆå°è¯•ä»å†…å±‚æ–‡æœ¬æå–draft_id
                        const innerMatch = this.extractDraftIdFromText(innerText);
                        if (innerMatch) {
                          draftId = innerMatch;
                          logger.info(`ğŸ“ X-MCP Auto-publish: Extracted draft_id "${draftId}" from nested JSON structure`);
                          break;
                        }
                      }
                    }
                  }
                } catch {
                  // å¦‚æœä¸æ˜¯JSONï¼Œç»§ç»­ç”¨åŸæ–‡æœ¬è¿›è¡Œæ¨¡å¼åŒ¹é…
                }
                
                // å¦‚æœåµŒå¥—è§£ææ²¡æœ‰æ‰¾åˆ°ï¼Œç”¨åŸæ–‡æœ¬è¿›è¡Œæ¨¡å¼åŒ¹é…
                if (!draftId) {
                  draftId = this.extractDraftIdFromText(text);
                  if (draftId) {
                    logger.info(`ğŸ“ X-MCP Auto-publish: Extracted draft_id "${draftId}" from text pattern matching`);
                  }
                }
                
                if (draftId) break;
              }
            }
          }
        }
      }
      
      // ğŸ”§ ä¿®å¤ï¼šå¤„ç†å­—ç¬¦ä¸²ç±»å‹çš„result
      if (!draftId && typeof result === 'string') {
        // ä»å­—ç¬¦ä¸²ç»“æœä¸­æå–
        try {
          const parsed = JSON.parse(result);
          if (parsed.draft_id) {
            draftId = parsed.draft_id;
          }
        } catch {
          // ğŸ”§ ä¿®å¤ï¼šå¤„ç†åµŒå¥—JSONå’Œå­—ç¬¦ä¸²æ–‡æœ¬ä¸­æå–draft ID
          draftId = this.extractDraftIdFromText(result);
          if (draftId) {
            logger.info(`ğŸ“ X-MCP Auto-publish: Extracted draft_id "${draftId}" from string pattern matching`);
          }
        }
      }

      if (!draftId) {
        logger.warn(`âš ï¸ X-MCP Auto-publish: Could not extract draft_id from result: ${JSON.stringify(result)}`);
        return result;
      }

      logger.info(`ğŸ“ X-MCP Auto-publish: Extracted draft_id: ${draftId}`);

            // è°ƒç”¨publish_draft
      logger.info(`ğŸš€ X-MCP Auto-publish: Publishing draft ${draftId}...`);
      
      const publishInput = { draft_id: draftId };
      logger.info(`ğŸ“ X-MCP Auto-publish INPUT: ${JSON.stringify(publishInput, null, 2)}`);
      
      const publishResult = await this.mcpToolAdapter.callTool(
        normalizedMcpName,
        'publish_draft',
        publishInput,
        userId
      );
      
      logger.info(`ğŸ“¤ X-MCP Auto-publish OUTPUT: ${JSON.stringify(publishResult, null, 2)}`);

      logger.info(`âœ… X-MCP Auto-publish: Successfully published draft ${draftId}`);

      // è¿”å›åˆå¹¶çš„ç»“æœ
      return {
        draft_creation: result,
        auto_publish: publishResult,
        combined_result: `Draft created and published successfully. Draft ID: ${draftId}`,
        draft_id: draftId,
        published: true
      };

    } catch (error) {
      logger.error(`âŒ X-MCP Auto-publish failed:`, error);
      
      // å³ä½¿å‘å¸ƒå¤±è´¥ï¼Œä¹Ÿè¿”å›åŸå§‹çš„è‰ç¨¿åˆ›å»ºç»“æœ
      return {
        draft_creation: result,
        auto_publish_error: error instanceof Error ? error.message : String(error),
        combined_result: `Draft created successfully but auto-publish failed. You may need to publish manually.`,
        published: false
      };
    }
  }

  /**
   * é€šç”¨LLM JSONå“åº”è§£æå‡½æ•°
   */
  private parseLLMJsonResponse(responseContent: string): any {
    const responseText = responseContent.toString().trim();
    
    console.log(`\n==== ğŸ“ LLM JSON Response Parsing Debug ====`);
    console.log(`Raw Response Length: ${responseText.length} chars`);
    console.log(`Raw Response: ${responseText}`);
    
    // ğŸ”§ æ”¹è¿›JSONè§£æï¼Œå…ˆæ¸…ç†LLMå“åº”ä¸­çš„é¢å¤–å†…å®¹
    let cleanedText = responseText;
    
    // ç§»é™¤Markdownä»£ç å—æ ‡è®°
    cleanedText = cleanedText.replace(/```json\n?/g, '').replace(/```\n?/g, '');
    console.log(`After Markdown Cleanup: ${cleanedText}`);
    
    // ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨æ›´æ™ºèƒ½çš„JSONæå–é€»è¾‘
    const extractedJson = this.extractCompleteJson(cleanedText);
    if (extractedJson) {
      cleanedText = extractedJson;
      console.log(`After JSON Extraction: ${cleanedText}`);
    }
    
    console.log(`ğŸ§¹ Final Cleaned text: ${cleanedText}`);
    
    try {
      const parsed = JSON.parse(cleanedText);
      console.log(`âœ… JSON.parse() successful`);
      console.log(`Parsed result: ${JSON.stringify(parsed, null, 2)}`);
      return parsed;
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      console.log(`âŒ JSON.parse() failed: ${errorMessage}`);
      logger.error(`Failed to parse LLM JSON response. Error: ${errorMessage}`);
      logger.error(`Original response: ${responseContent}`);
      throw new Error(`JSON parsing failed: ${errorMessage}`);
    }
  }

  /**
   * æ™ºèƒ½æå–å®Œæ•´çš„JSONå¯¹è±¡
   */
  private extractCompleteJson(text: string): string | null {
    // æŸ¥æ‰¾ç¬¬ä¸€ä¸ª '{' çš„ä½ç½®
    const startIndex = text.indexOf('{');
    if (startIndex === -1) {
      return null;
    }
    
    // ä» '{' å¼€å§‹ï¼Œæ‰‹åŠ¨åŒ¹é…å¤§æ‹¬å·ä»¥æ‰¾åˆ°å®Œæ•´çš„JSONå¯¹è±¡
    let braceCount = 0;
    let inString = false;
    let escapeNext = false;
    
    for (let i = startIndex; i < text.length; i++) {
      const char = text[i];
      
      if (escapeNext) {
        escapeNext = false;
        continue;
      }
      
      if (char === '\\' && inString) {
        escapeNext = true;
        continue;
      }
      
      if (char === '"' && !escapeNext) {
        inString = !inString;
        continue;
      }
      
      if (!inString) {
        if (char === '{') {
          braceCount++;
        } else if (char === '}') {
          braceCount--;
          
          // å½“å¤§æ‹¬å·è®¡æ•°ä¸º0æ—¶ï¼Œæˆ‘ä»¬æ‰¾åˆ°äº†å®Œæ•´çš„JSONå¯¹è±¡
          if (braceCount === 0) {
            const jsonString = text.substring(startIndex, i + 1);
            console.log(`ğŸ”§ Extracted complete JSON: ${jsonString}`);
            return jsonString;
          }
        }
      }
    }
    
    // å¦‚æœæ²¡æœ‰æ‰¾åˆ°å®Œæ•´çš„JSONå¯¹è±¡ï¼Œè¿”å›null
    console.log(`âš ï¸ Could not find complete JSON object`);
    return null;
  }

  /**
   * ä½¿ç”¨LLMæµå¼æ ¼å¼åŒ–ç»“æœ
   * @param rawResult åŸå§‹ç»“æœ
   * @param mcpName MCPåç§°
   * @param actionName æ“ä½œåç§°
   * @param streamCallback æµå¼å›è°ƒå‡½æ•°
   */
  private async formatResultWithLLMStream(
    rawResult: any, 
    mcpName: string, 
    actionName: string,
    streamCallback: (chunk: string) => void,
    userLanguage?: SupportedLanguage
  ): Promise<string> {
    try {
      logger.info(`ğŸ¤– Using LLM to format result for ${mcpName}/${actionName} (streaming)`);
      
      // æå–å®é™…å†…å®¹
      let actualContent = rawResult;
      if (rawResult && typeof rawResult === 'object' && rawResult.content) {
        if (Array.isArray(rawResult.content) && rawResult.content.length > 0) {
          actualContent = rawResult.content[0].text || rawResult.content[0];
        } else if (rawResult.content.text) {
          actualContent = rawResult.content.text;
        } else {
          actualContent = rawResult.content;
        }
      }
      
      // ğŸŒ å¦‚æœæ²¡æœ‰ä¼ å…¥ç”¨æˆ·è¯­è¨€ï¼Œå°è¯•ä»åŸå§‹æ•°æ®ä¸­æ£€æµ‹
      if (!userLanguage && typeof actualContent === 'string') {
        userLanguage = resolveUserLanguage(actualContent);
      }
      
      // ğŸ”§ ç§»é™¤å†…å®¹é•¿åº¦é™åˆ¶ï¼Œå…è®¸å¤„ç†å®Œæ•´æ•°æ®
      // æ³¨é‡Šï¼šä¸ºäº†è·å–å®Œæ•´çš„ MCP æ•°æ®ï¼Œç§»é™¤äº†ä¹‹å‰çš„ 50K å­—ç¬¦é™åˆ¶
      const contentStr = typeof actualContent === 'string' ? actualContent : JSON.stringify(actualContent, null, 2);
      // const MAX_CONTENT_LENGTH = 50000; // å·²ç§»é™¤ 50kå­—ç¬¦é™åˆ¶
      
      let processedContent = contentStr;
      // ç§»é™¤å†…å®¹æˆªæ–­é€»è¾‘
      // if (contentStr.length > MAX_CONTENT_LENGTH) {
      //   processedContent = contentStr.substring(0, MAX_CONTENT_LENGTH) + '\n... (content truncated due to length)';
      //   logger.warn(`Content truncated from ${contentStr.length} to ${MAX_CONTENT_LENGTH} characters`);
      // }
      
      // æ„å»ºæ ¼å¼åŒ–æç¤ºè¯
      const formatPrompt = `You are a professional data presentation specialist. Your task is to extract useful information from raw API/tool responses and present it in a clean, readable Markdown format.

MCP Tool: ${mcpName}
Action: ${actionName}
Raw Result:
${processedContent}

FORMATTING RULES:
1. **Smart Data Recognition**: Analyze the raw result to identify if it contains:
   - Valid data (JSON arrays, objects, structured information)
   - Error messages or failures
   - Mixed results (some data with warnings/errors)

2. **Format Based on Content Type**:
   - **Valid Data**: Extract and present the meaningful information
   - **Error Results**: Explain what went wrong in user-friendly terms
   - **Mixed Results**: Present available data and note any issues

3. **Presentation Guidelines**:
   - Use proper Markdown formatting (headers, lists, tables, etc.)
   - Highlight important numbers, dates, and key information
   - Remove technical details, error codes, and unnecessary metadata
   - If the result contains financial data, format numbers properly (e.g., $1,234.56)
   - Include relevant links, images, or references if available
   - Structure the information logically with clear sections

4. **Quality Standards**:
   - Be concise but comprehensive
   - Focus on user-actionable information
   - Maintain professional tone
   - Ensure the output is immediately useful to the end user

ğŸš¨ CRITICAL: Return ONLY the raw Markdown content without any code block wrappers. 
âŒ DO NOT wrap your response in \`\`\`markdown \`\`\` or \`\`\` \`\`\` blocks.
âœ… Return the markdown content directly, ready for immediate display.

IMPORTANT: Your response should be ready-to-display markdown content, not wrapped in any code blocks.${userLanguage ? getLanguageInstruction(userLanguage) : ''}`;

      // åˆ›å»ºæµå¼LLMå®ä¾‹
      const streamingLLM = new ChatOpenAI({
        modelName: 'gpt-4o',
        temperature: 0.3,
        maxTokens: 16384,
        streaming: true,
        apiKey: process.env.OPENAI_API_KEY
      });

      let fullResult = '';
      let isFirstChunk = true;
      let hasMarkdownWrapper = false;
      
      // ä½¿ç”¨æµå¼è°ƒç”¨
      const stream = await streamingLLM.stream([
        new SystemMessage(formatPrompt)
      ]);

      for await (const chunk of stream) {
        const content = chunk.content.toString();
        if (content) {
          // ğŸ”§ å…³é”®ä¿®å¤ï¼šæ£€æµ‹å¹¶å¤„ç†markdownä»£ç å—åŒ…è£…
          if (isFirstChunk && content.includes('```markdown')) {
            hasMarkdownWrapper = true;
            // ç§»é™¤å¼€å¤´çš„```markdown\n
            const cleanContent = content.replace(/^.*?```markdown\s*\n?/s, '');
            if (cleanContent) {
              fullResult += cleanContent;
              streamCallback(cleanContent);
            }
          } else if (hasMarkdownWrapper && content.includes('```')) {
            // ç§»é™¤ç»“å°¾çš„\n```
            const cleanContent = content.replace(/\n?```.*$/s, '');
            if (cleanContent) {
              fullResult += cleanContent;
              streamCallback(cleanContent);
            }
            hasMarkdownWrapper = false; // æ ‡è®°åŒ…è£…å·²ç»“æŸ
          } else if (!hasMarkdownWrapper || !content.trim().startsWith('```')) {
            fullResult += content;
            streamCallback(content);
          }
          isFirstChunk = false;
        }
      }
      
      // ğŸ”§ é¢å¤–æ¸…ç†ï¼šå¦‚æœè¿˜æœ‰æ®‹ç•™çš„markdownåŒ…è£…
      if (fullResult.startsWith('```markdown\n') && fullResult.endsWith('\n```')) {
        fullResult = fullResult.slice(12, -4).trim();
        logger.info(`ğŸ”§ Cleaned residual markdown wrapper in stream`);
      }
      
      logger.info(`âœ… Result formatted successfully with streaming`);
      return fullResult.trim();
      
    } catch (error) {
      logger.error(`Failed to format result with LLM (streaming):`, error);
      
      // é™çº§å¤„ç†ï¼šè¿”å›åŸºæœ¬æ ¼å¼åŒ–çš„ç»“æœ
      const fallbackResult = `### ${actionName} ç»“æœ\n\n\`\`\`json\n${JSON.stringify(rawResult, null, 2)}\n\`\`\``;
      streamCallback(fallbackResult);
      return fallbackResult;
    }
  }

  /**
   * Check if error type is MCP connection related
   */
  private isMCPConnectionError(errorType: string): boolean {
    const mcpConnectionErrorTypes = [
      'INVALID_API_KEY',
      'EXPIRED_API_KEY', 
      'WRONG_PASSWORD',
      'MISSING_AUTH_PARAMS',
      'INVALID_AUTH_FORMAT',
      'INSUFFICIENT_PERMISSIONS',
      'MCP_CONNECTION_FAILED',
      'MCP_AUTH_REQUIRED',
      'MCP_SERVICE_INIT_FAILED'
    ];
    return mcpConnectionErrorTypes.includes(errorType);
  }

  /**
   * ğŸ”§ æ–°å¢ï¼šéªŒè¯å‚æ•°åæ˜¯å¦ä¸å·¥å…· schema åŒ¹é…
   */
  private validateParameterNames(params: any, inputSchema: any): any {
    if (!params || typeof params !== 'object') {
      return params;
    }

    if (!inputSchema || !inputSchema.properties) {
      return params;
    }

    const schemaProperties = inputSchema.properties;
    const expectedParamNames = Object.keys(schemaProperties);
    
    logger.info(`ğŸ”§ Validating parameters, expected: [${expectedParamNames.join(', ')}]`);

    const validatedParams: any = {};
    
    for (const [key, value] of Object.entries(params)) {
      let finalKey = key;
      
      // å¦‚æœå‚æ•°åä¸åœ¨æœŸæœ›åˆ—è¡¨ä¸­ï¼Œå°è¯•è½¬æ¢
      if (!expectedParamNames.includes(key)) {
        const snakeCaseKey = this.camelToSnakeCase(key);
        if (expectedParamNames.includes(snakeCaseKey)) {
          finalKey = snakeCaseKey;
          logger.info(`ğŸ”§ Parameter name corrected: ${key} -> ${finalKey}`);
        } else {
          logger.warn(`âš ï¸ Parameter ${key} not found in schema, keeping original name`);
        }
      }
      
      validatedParams[finalKey] = value;
    }

    return validatedParams;
  }

  /**
   * ğŸ”§ æ–°å¢ï¼šcamelCase è½¬ snake_case
   */
  private camelToSnakeCase(str: string): string {
    return str.replace(/([a-z])([A-Z])/g, '$1_$2').toLowerCase();
  }
} 